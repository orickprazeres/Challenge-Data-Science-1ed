{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mirlaa/Challenge-Data-Science-1ed/blob/main/semana-2/Challenge_de_Dados_Semana_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ9Qh-yE0fOW"
      },
      "source": [
        "# <h1 style=\"padding:0px; background-color:#0f4c5c; margin:0; color:white; font-family:newtimeroman; font-size:300%; text-align:center;border-radius: 25px 25px; overflow:hidden; font-weight:500\">Challenge de Data Science - Semana 2<br></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE-5Xukghqh9"
      },
      "source": [
        "<div align=\"center\"> <img src=\"https://i.imgur.com/oxab3uu.png\" width=\"800px\" /> </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq-_NCqQhXqq"
      },
      "source": [
        "### Introdução\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qd59xrRhZUn"
      },
      "source": [
        "\n",
        "Na semana 2 buscamos construir um modelo de ML que pudesse predizer de acordo com os dados bancários de cada cliente, se essa pessoa pode ou não se tornar inadimplente. Dessa vez, utilizamos o Python no ambiente do Google Colab para desenvolver nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bibliotecas usadas:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# importes parciais realizados(em ordem de uso):\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import recall_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8UhJRpW0iCb"
      },
      "source": [
        "## <h1 style=\"padding:10px;background-color:orange;margin:0;color:black;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 25px 25px;overflow:hidden;font-weight:500\">Dados para Análise</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "UzSFv3X97Jn2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_age</th>\n",
              "      <th>person_income</th>\n",
              "      <th>person_home_ownership</th>\n",
              "      <th>person_emp_length</th>\n",
              "      <th>loan_intent</th>\n",
              "      <th>loan_grade</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>loan_int_rate</th>\n",
              "      <th>loan_status</th>\n",
              "      <th>loan_percent_income</th>\n",
              "      <th>cb_person_default_on_file</th>\n",
              "      <th>cb_person_cred_hist_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>60000</td>\n",
              "      <td>Rent</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>B</td>\n",
              "      <td>8000</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0.13</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>70000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>A</td>\n",
              "      <td>18000</td>\n",
              "      <td>7.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>N</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>115000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>C</td>\n",
              "      <td>22000</td>\n",
              "      <td>15.23</td>\n",
              "      <td>0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>Y</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26</td>\n",
              "      <td>84996</td>\n",
              "      <td>Rent</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>B</td>\n",
              "      <td>9000</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0.11</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23</td>\n",
              "      <td>54500</td>\n",
              "      <td>Rent</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Debtconsolidation</td>\n",
              "      <td>A</td>\n",
              "      <td>8000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
              "0          21          60000                  Rent                2.0   \n",
              "1          40          70000              Mortgage                6.0   \n",
              "2          29         115000              Mortgage                3.0   \n",
              "3          26          84996                  Rent                0.0   \n",
              "4          23          54500                  Rent                2.0   \n",
              "\n",
              "         loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
              "0          Education          B       8000          11.26            0   \n",
              "1          Education          A      18000           7.90            0   \n",
              "2            Medical          C      22000          15.23            0   \n",
              "3            Medical          B       9000          11.26            0   \n",
              "4  Debtconsolidation          A       8000           0.00            0   \n",
              "\n",
              "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
              "0                 0.13                         N                           3  \n",
              "1                 0.26                         N                          14  \n",
              "2                 0.19                         Y                           7  \n",
              "3                 0.11                         N                           2  \n",
              "4                 0.15                         N                           2  "
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados = pd.read_csv('../Dados/dados_juntos.csv')\n",
        "dados.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPD1jnq8kD3z"
      },
      "source": [
        "### Traduzindo o nome das colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mozW6J9UjaEo"
      },
      "source": [
        "Os nomes das colunas do DataFrame estão todos em inglês, o que prejudica a interpretação das variáveis. Vamos criar um dicionário para traduzir o nome das colunas para o português."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "BybOb-zW8BFW"
      },
      "outputs": [],
      "source": [
        "dicionario = {\n",
        "    'person_age': 'idade',\n",
        "    'person_income': 'salario',\n",
        "    'person_home_ownership': 'situacao_moradia',\n",
        "    'person_emp_length': 'tempo_trabalho',\n",
        "    'loan_intent': 'motivo_emprestimo',\n",
        "    'loan_grade': 'pontuacao_emprestimo',\n",
        "    'loan_amnt': 'valor_emprestimo',\n",
        "    'loan_int_rate': 'taxa_juros',\n",
        "    'loan_status': 'inadimplencia',\n",
        "    'loan_percent_income': 'renda_percentual_emprestimo',\n",
        "    'cb_person_default_on_file': 'devendo',\n",
        "    'cb_person_cred_hist_length': 'tempo_de_credito'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "NVt36FpT-C20"
      },
      "outputs": [],
      "source": [
        "dados.rename(dicionario, axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <h1 style=\"padding:10px;background-color:orange;margin:0;color:black;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 25px 25px;overflow:hidden;font-weight:500\">Análise Preliminardas dos Dados</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJQFSgaanWQt"
      },
      "source": [
        "Vamos iniciar o processo de análise dos dados para identificação de valores inconsistentes, presença de outliers e dados nulos que podem prejudicar o modelo de aprendizado de máquina.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSH6ZoPNkdaP"
      },
      "source": [
        "Vamos utilizar o método `info()` para identificar a presença de dados nulos e dtypes das colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gPUUir37hvW",
        "outputId": "11481b40-1760-4703-e3f1-a6a8f28d7410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34501 entries, 0 to 34500\n",
            "Data columns (total 12 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   idade                        34501 non-null  int64  \n",
            " 1   salario                      34501 non-null  int64  \n",
            " 2   situacao_moradia             34170 non-null  object \n",
            " 3   tempo_trabalho               34501 non-null  float64\n",
            " 4   motivo_emprestimo            34186 non-null  object \n",
            " 5   pontuacao_emprestimo         34188 non-null  object \n",
            " 6   valor_emprestimo             34501 non-null  int64  \n",
            " 7   taxa_juros                   34501 non-null  float64\n",
            " 8   inadimplencia                34501 non-null  int64  \n",
            " 9   renda_percentual_emprestimo  34501 non-null  float64\n",
            " 10  devendo                      34131 non-null  object \n",
            " 11  tempo_de_credito             34501 non-null  int64  \n",
            "dtypes: float64(3), int64(5), object(4)\n",
            "memory usage: 3.2+ MB\n"
          ]
        }
      ],
      "source": [
        "dados.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3adQo8dZn1ii"
      },
      "source": [
        "* É possível identificar a presença de dados nulos nas colunas, que deverão ser tratadas posteriormente. \n",
        "* As variáveis `situacao_moradia`, `motivo_emprestimo`, `pontuacao_emprestimo` e `devendo` apresentam o dtype object e deverão passar por algum tratamento para serem utilizados na etapa de modelagem.\n",
        "* O conjunto de dados possui 34501 registros e um total de 12 colunas.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eyoQyvirCon"
      },
      "source": [
        "O método `describe()` por padrão traz informações a respeito de cada uma das variáveis numéricas, o que auxilia na identificação de outliers, e fornece uma ideia geral da distribuição dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "hJvPdl6jGX7L",
        "outputId": "b14fc56c-7fb1-4321-93d0-e96988269a07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>idade</th>\n",
              "      <td>34501.0</td>\n",
              "      <td>27.4706</td>\n",
              "      <td>6.8585</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.00</td>\n",
              "      <td>26.00</td>\n",
              "      <td>30.00</td>\n",
              "      <td>144.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>salario</th>\n",
              "      <td>34501.0</td>\n",
              "      <td>65379.9031</td>\n",
              "      <td>61448.7573</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38000.00</td>\n",
              "      <td>55000.00</td>\n",
              "      <td>78750.00</td>\n",
              "      <td>6000000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tempo_trabalho</th>\n",
              "      <td>34501.0</td>\n",
              "      <td>4.6132</td>\n",
              "      <td>4.1592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>123.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valor_emprestimo</th>\n",
              "      <td>34501.0</td>\n",
              "      <td>9498.5653</td>\n",
              "      <td>6359.1317</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5000.00</td>\n",
              "      <td>8000.00</td>\n",
              "      <td>12000.00</td>\n",
              "      <td>35000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>taxa_juros</th>\n",
              "      <td>34501.0</td>\n",
              "      <td>9.8548</td>\n",
              "      <td>4.5629</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.49</td>\n",
              "      <td>10.59</td>\n",
              "      <td>13.11</td>\n",
              "      <td>23.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>inadimplencia</th>\n",
              "      <td>34501.0</td>\n",
              "      <td>0.2160</td>\n",
              "      <td>0.4115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>renda_percentual_emprestimo</th>\n",
              "      <td>34501.0</td>\n",
              "      <td>0.1687</td>\n",
              "      <td>0.1075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tempo_de_credito</th>\n",
              "      <td>34501.0</td>\n",
              "      <td>5.8075</td>\n",
              "      <td>4.0635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>8.00</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               count        mean         std  min       25%  \\\n",
              "idade                        34501.0     27.4706      6.8585  0.0     23.00   \n",
              "salario                      34501.0  65379.9031  61448.7573  0.0  38000.00   \n",
              "tempo_trabalho               34501.0      4.6132      4.1592  0.0      2.00   \n",
              "valor_emprestimo             34501.0   9498.5653   6359.1317  0.0   5000.00   \n",
              "taxa_juros                   34501.0      9.8548      4.5629  0.0      7.49   \n",
              "inadimplencia                34501.0      0.2160      0.4115  0.0      0.00   \n",
              "renda_percentual_emprestimo  34501.0      0.1687      0.1075  0.0      0.09   \n",
              "tempo_de_credito             34501.0      5.8075      4.0635  0.0      3.00   \n",
              "\n",
              "                                  50%       75%         max  \n",
              "idade                           26.00     30.00      144.00  \n",
              "salario                      55000.00  78750.00  6000000.00  \n",
              "tempo_trabalho                   4.00      7.00      123.00  \n",
              "valor_emprestimo              8000.00  12000.00    35000.00  \n",
              "taxa_juros                      10.59     13.11       23.22  \n",
              "inadimplencia                    0.00      0.00        1.00  \n",
              "renda_percentual_emprestimo      0.15      0.23        0.83  \n",
              "tempo_de_credito                 4.00      8.00       30.00  "
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados.describe().round(4).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXbOdzEBsupN"
      },
      "source": [
        "Foi possível a identificação de valores discrepantes para as variáveis `idade` e `tempo_trabalho`.\n",
        "\n",
        "Uma idade máxima de 144 anos e um tempo de trabalho de 123 são dados que não fazem sentido e serão removidos posteriormente do conjunto de dados.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFmDQmAGwMYW"
      },
      "source": [
        "Vamos checar os dados únicos de cada uma das variáveis categóricas para identificar se há a presença de valores nulos e a quantidade de categorias de cada uma das colunas, indicando qual tratamento precisa ser feito antes de seguir para a modelagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNJosKwaI06P",
        "outputId": "21df568e-295c-443e-d3b6-82731c1bbe6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Rent', 'Mortgage', 'Own', 'Other', nan], dtype=object)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados['situacao_moradia'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hHPnZwzJDLO",
        "outputId": "9173bfee-873a-4e32-80f2-c2ec7c8cff12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Education', 'Medical', 'Debtconsolidation', 'Personal', 'Venture',\n",
              "       'Homeimprovement', nan], dtype=object)"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados['motivo_emprestimo'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjVUy8IsJEef",
        "outputId": "6f5b3f82-639c-4bf5-a29d-56bac35ae0e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['B', 'A', 'C', 'D', 'E', 'F', nan, 'G'], dtype=object)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados['pontuacao_emprestimo'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YFfGNoaJJCm",
        "outputId": "42d5486a-7c0d-4896-ef0c-bd87a6b8ad70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['N', 'Y', nan], dtype=object)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados['devendo'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colunas com dados nulos ou não preenchidos: \n",
            "situacao_moradia        331\n",
            "motivo_emprestimo       315\n",
            "pontuacao_emprestimo    313\n",
            "devendo                 370\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "colunas_nulas = dados[['situacao_moradia', 'motivo_emprestimo', 'pontuacao_emprestimo', 'devendo' ]].isnull().sum()\n",
        "print(f'Colunas com dados nulos ou não preenchidos: \\n{colunas_nulas}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1K-m4Rw6RA"
      },
      "source": [
        "\n",
        "\n",
        "* Todas as colunas categóricas possuem dados nulos que serão removidos\n",
        "* As colunas `situacao_moradia`, `motivo_emprestimo` e `pontuacao_emprestimo` possuem mais de 2 categorias, portanto o procedimento de *one hot encoding* precisa ser realizado\n",
        "* A coluna `devendo` possui duas categorias, portanto uma substituição desses valores para 0 e 1 será feita.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Ij_bNytsWOKB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.783977\n",
              "1    0.216023\n",
              "Name: inadimplencia, dtype: float64"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados['inadimplencia'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFN7rcgNWUPn"
      },
      "source": [
        "É possível identificar que a variável alvo é desbalanceada, o que pode acarretar em problemas na etapa de modelagem.\n",
        "\n",
        "Podemos utilizar técnicas para realizar o balançeamento de dados posteriomente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV8HM7Zh0urb"
      },
      "source": [
        "## <h1 style=\"padding:10px;background-color:orange;margin:0;color:black;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 25px 25px;overflow:hidden;font-weight:500\">Limpeza dos dados</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoojlWm7yE73"
      },
      "source": [
        "Vamos iniciar o processo de limpeza dos dados a partir da análise que foi realizada na etapa anterior.\n",
        "\n",
        "Vamos checar a quantidade de registros antes e após a limpeza de dados nulos para descobrir quantos dados serão perdidos no processo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3B5udF5F92Y",
        "outputId": "d3bd7426-a34e-424f-aea9-b900b8f09c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantidade de registros: 34501\n"
          ]
        }
      ],
      "source": [
        "print(f'Quantidade de registros: {dados.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cPh69wxF2mF",
        "outputId": "5b4bd12e-af06-45fe-ef38-a22c3618eba0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "idade                            0\n",
              "salario                          0\n",
              "situacao_moradia               331\n",
              "tempo_trabalho                   0\n",
              "motivo_emprestimo              315\n",
              "pontuacao_emprestimo           313\n",
              "valor_emprestimo                 0\n",
              "taxa_juros                       0\n",
              "inadimplencia                    0\n",
              "renda_percentual_emprestimo      0\n",
              "devendo                        370\n",
              "tempo_de_credito                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzGK9ST2zMoG"
      },
      "source": [
        "A quantidade de dados nulos em relação à quantidade de registros total do conjunto de dados é muito pequena, portanto serão removidos sem perda de muita informação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "TcJdZoi5AQaN"
      },
      "outputs": [],
      "source": [
        "dados.dropna(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "hVWtMJxLEA-u",
        "outputId": "c4ea42e6-8094-420c-ff9d-95c961bbad60"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idade</th>\n",
              "      <th>salario</th>\n",
              "      <th>situacao_moradia</th>\n",
              "      <th>tempo_trabalho</th>\n",
              "      <th>motivo_emprestimo</th>\n",
              "      <th>pontuacao_emprestimo</th>\n",
              "      <th>valor_emprestimo</th>\n",
              "      <th>taxa_juros</th>\n",
              "      <th>inadimplencia</th>\n",
              "      <th>renda_percentual_emprestimo</th>\n",
              "      <th>devendo</th>\n",
              "      <th>tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>60000</td>\n",
              "      <td>Rent</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>B</td>\n",
              "      <td>8000</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0.13</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>70000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>A</td>\n",
              "      <td>18000</td>\n",
              "      <td>7.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>N</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>115000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>C</td>\n",
              "      <td>22000</td>\n",
              "      <td>15.23</td>\n",
              "      <td>0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>Y</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26</td>\n",
              "      <td>84996</td>\n",
              "      <td>Rent</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>B</td>\n",
              "      <td>9000</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0.11</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23</td>\n",
              "      <td>54500</td>\n",
              "      <td>Rent</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Debtconsolidation</td>\n",
              "      <td>A</td>\n",
              "      <td>8000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34496</th>\n",
              "      <td>39</td>\n",
              "      <td>33996</td>\n",
              "      <td>Rent</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>D</td>\n",
              "      <td>4000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.12</td>\n",
              "      <td>N</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34497</th>\n",
              "      <td>24</td>\n",
              "      <td>36000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Homeimprovement</td>\n",
              "      <td>A</td>\n",
              "      <td>14775</td>\n",
              "      <td>6.62</td>\n",
              "      <td>0</td>\n",
              "      <td>0.41</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34498</th>\n",
              "      <td>27</td>\n",
              "      <td>39600</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Debtconsolidation</td>\n",
              "      <td>A</td>\n",
              "      <td>4800</td>\n",
              "      <td>6.76</td>\n",
              "      <td>0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>N</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34499</th>\n",
              "      <td>30</td>\n",
              "      <td>39996</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>C</td>\n",
              "      <td>10000</td>\n",
              "      <td>12.73</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>N</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34500</th>\n",
              "      <td>26</td>\n",
              "      <td>54996</td>\n",
              "      <td>Rent</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>B</td>\n",
              "      <td>20000</td>\n",
              "      <td>12.18</td>\n",
              "      <td>1</td>\n",
              "      <td>0.36</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33364 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       idade  salario situacao_moradia  tempo_trabalho  motivo_emprestimo  \\\n",
              "0         21    60000             Rent             2.0          Education   \n",
              "1         40    70000         Mortgage             6.0          Education   \n",
              "2         29   115000         Mortgage             3.0            Medical   \n",
              "3         26    84996             Rent             0.0            Medical   \n",
              "4         23    54500             Rent             2.0  Debtconsolidation   \n",
              "...      ...      ...              ...             ...                ...   \n",
              "34496     39    33996             Rent             6.0            Medical   \n",
              "34497     24    36000         Mortgage             0.0    Homeimprovement   \n",
              "34498     27    39600         Mortgage            11.0  Debtconsolidation   \n",
              "34499     30    39996         Mortgage             8.0            Medical   \n",
              "34500     26    54996             Rent             8.0          Education   \n",
              "\n",
              "      pontuacao_emprestimo  valor_emprestimo  taxa_juros  inadimplencia  \\\n",
              "0                        B              8000       11.26              0   \n",
              "1                        A             18000        7.90              0   \n",
              "2                        C             22000       15.23              0   \n",
              "3                        B              9000       11.26              0   \n",
              "4                        A              8000        0.00              0   \n",
              "...                    ...               ...         ...            ...   \n",
              "34496                    D              4000        0.00              1   \n",
              "34497                    A             14775        6.62              0   \n",
              "34498                    A              4800        6.76              0   \n",
              "34499                    C             10000       12.73              0   \n",
              "34500                    B             20000       12.18              1   \n",
              "\n",
              "       renda_percentual_emprestimo devendo  tempo_de_credito  \n",
              "0                             0.13       N                 3  \n",
              "1                             0.26       N                14  \n",
              "2                             0.19       Y                 7  \n",
              "3                             0.11       N                 2  \n",
              "4                             0.15       N                 2  \n",
              "...                            ...     ...               ...  \n",
              "34496                         0.12       N                13  \n",
              "34497                         0.41       N                 4  \n",
              "34498                         0.12       N                 9  \n",
              "34499                         0.25       N                 6  \n",
              "34500                         0.36       N                 4  \n",
              "\n",
              "[33364 rows x 12 columns]"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9F1sMm5GODV",
        "outputId": "9e61a515-9791-498f-a344-01590a683efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantidade de registros: 33364\n"
          ]
        }
      ],
      "source": [
        "print(f'Quantidade de registros: {dados.shape[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax1ZiY3b0WS1"
      },
      "source": [
        "A quantidade de registros inicial era de 34501 e a final de 33364.\n",
        "\n",
        "Foram removidos 1137 registros do conjunto de dados inicial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Discrepância <hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVLrJvmH0wfb"
      },
      "source": [
        "Vamos agora identificar quais dados são discrepantes e remover do conjunto de dados.\n",
        "\n",
        "Filtraremos valores com idade maior que 100 anos e tempo de trabalho maior que 90 anos, apenas para critério de ponto de corte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "8oljmjvlEH_k",
        "outputId": "72e40b83-3c53-4e46-b36a-d0042a1be48f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idade</th>\n",
              "      <th>salario</th>\n",
              "      <th>situacao_moradia</th>\n",
              "      <th>tempo_trabalho</th>\n",
              "      <th>motivo_emprestimo</th>\n",
              "      <th>pontuacao_emprestimo</th>\n",
              "      <th>valor_emprestimo</th>\n",
              "      <th>taxa_juros</th>\n",
              "      <th>inadimplencia</th>\n",
              "      <th>renda_percentual_emprestimo</th>\n",
              "      <th>devendo</th>\n",
              "      <th>tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13850</th>\n",
              "      <td>144</td>\n",
              "      <td>6000000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Personal</td>\n",
              "      <td>C</td>\n",
              "      <td>5000</td>\n",
              "      <td>12.73</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>N</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17272</th>\n",
              "      <td>123</td>\n",
              "      <td>80004</td>\n",
              "      <td>Rent</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>B</td>\n",
              "      <td>20400</td>\n",
              "      <td>10.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22137</th>\n",
              "      <td>144</td>\n",
              "      <td>200000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>B</td>\n",
              "      <td>6000</td>\n",
              "      <td>11.86</td>\n",
              "      <td>0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23737</th>\n",
              "      <td>123</td>\n",
              "      <td>78000</td>\n",
              "      <td>Rent</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Venture</td>\n",
              "      <td>B</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29224</th>\n",
              "      <td>144</td>\n",
              "      <td>250000</td>\n",
              "      <td>Rent</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Venture</td>\n",
              "      <td>C</td>\n",
              "      <td>4800</td>\n",
              "      <td>13.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       idade  salario situacao_moradia  tempo_trabalho motivo_emprestimo  \\\n",
              "13850    144  6000000         Mortgage            12.0          Personal   \n",
              "17272    123    80004             Rent             2.0         Education   \n",
              "22137    144   200000         Mortgage             4.0         Education   \n",
              "23737    123    78000             Rent             7.0           Venture   \n",
              "29224    144   250000             Rent             4.0           Venture   \n",
              "\n",
              "      pontuacao_emprestimo  valor_emprestimo  taxa_juros  inadimplencia  \\\n",
              "13850                    C              5000       12.73              0   \n",
              "17272                    B             20400       10.25              0   \n",
              "22137                    B              6000       11.86              0   \n",
              "23737                    B             20000        0.00              0   \n",
              "29224                    C              4800       13.57              0   \n",
              "\n",
              "       renda_percentual_emprestimo devendo  tempo_de_credito  \n",
              "13850                         0.00       N                25  \n",
              "17272                         0.25       N                 3  \n",
              "22137                         0.03       N                 2  \n",
              "23737                         0.26       N                 4  \n",
              "29224                         0.02       N                 3  "
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados[(dados['idade'] > 100)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "T3u8IuwcErae",
        "outputId": "cd8d7e72-7325-455e-ee5e-9abf45e248bb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idade</th>\n",
              "      <th>salario</th>\n",
              "      <th>situacao_moradia</th>\n",
              "      <th>tempo_trabalho</th>\n",
              "      <th>motivo_emprestimo</th>\n",
              "      <th>pontuacao_emprestimo</th>\n",
              "      <th>valor_emprestimo</th>\n",
              "      <th>taxa_juros</th>\n",
              "      <th>inadimplencia</th>\n",
              "      <th>renda_percentual_emprestimo</th>\n",
              "      <th>devendo</th>\n",
              "      <th>tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8200</th>\n",
              "      <td>22</td>\n",
              "      <td>59000</td>\n",
              "      <td>Rent</td>\n",
              "      <td>123.0</td>\n",
              "      <td>Personal</td>\n",
              "      <td>D</td>\n",
              "      <td>35000</td>\n",
              "      <td>16.02</td>\n",
              "      <td>1</td>\n",
              "      <td>0.59</td>\n",
              "      <td>Y</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21177</th>\n",
              "      <td>21</td>\n",
              "      <td>192000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>123.0</td>\n",
              "      <td>Venture</td>\n",
              "      <td>A</td>\n",
              "      <td>20000</td>\n",
              "      <td>6.54</td>\n",
              "      <td>0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       idade  salario situacao_moradia  tempo_trabalho motivo_emprestimo  \\\n",
              "8200      22    59000             Rent           123.0          Personal   \n",
              "21177     21   192000         Mortgage           123.0           Venture   \n",
              "\n",
              "      pontuacao_emprestimo  valor_emprestimo  taxa_juros  inadimplencia  \\\n",
              "8200                     D             35000       16.02              1   \n",
              "21177                    A             20000        6.54              0   \n",
              "\n",
              "       renda_percentual_emprestimo devendo  tempo_de_credito  \n",
              "8200                          0.59       Y                 3  \n",
              "21177                         0.10       N                 4  "
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados[(dados['tempo_trabalho'] > 90)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "hLwPF6J2BiWB",
        "outputId": "c3bdc23a-42f4-45e4-8cc9-cb8cbe921d7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idade</th>\n",
              "      <th>salario</th>\n",
              "      <th>situacao_moradia</th>\n",
              "      <th>tempo_trabalho</th>\n",
              "      <th>motivo_emprestimo</th>\n",
              "      <th>pontuacao_emprestimo</th>\n",
              "      <th>valor_emprestimo</th>\n",
              "      <th>taxa_juros</th>\n",
              "      <th>inadimplencia</th>\n",
              "      <th>renda_percentual_emprestimo</th>\n",
              "      <th>devendo</th>\n",
              "      <th>tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>60000</td>\n",
              "      <td>Rent</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>B</td>\n",
              "      <td>8000</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0.13</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>70000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>A</td>\n",
              "      <td>18000</td>\n",
              "      <td>7.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>N</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>115000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>C</td>\n",
              "      <td>22000</td>\n",
              "      <td>15.23</td>\n",
              "      <td>0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>Y</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26</td>\n",
              "      <td>84996</td>\n",
              "      <td>Rent</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>B</td>\n",
              "      <td>9000</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0</td>\n",
              "      <td>0.11</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23</td>\n",
              "      <td>54500</td>\n",
              "      <td>Rent</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Debtconsolidation</td>\n",
              "      <td>A</td>\n",
              "      <td>8000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34496</th>\n",
              "      <td>39</td>\n",
              "      <td>33996</td>\n",
              "      <td>Rent</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>D</td>\n",
              "      <td>4000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.12</td>\n",
              "      <td>N</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34497</th>\n",
              "      <td>24</td>\n",
              "      <td>36000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Homeimprovement</td>\n",
              "      <td>A</td>\n",
              "      <td>14775</td>\n",
              "      <td>6.62</td>\n",
              "      <td>0</td>\n",
              "      <td>0.41</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34498</th>\n",
              "      <td>27</td>\n",
              "      <td>39600</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Debtconsolidation</td>\n",
              "      <td>A</td>\n",
              "      <td>4800</td>\n",
              "      <td>6.76</td>\n",
              "      <td>0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>N</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34499</th>\n",
              "      <td>30</td>\n",
              "      <td>39996</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>C</td>\n",
              "      <td>10000</td>\n",
              "      <td>12.73</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>N</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34500</th>\n",
              "      <td>26</td>\n",
              "      <td>54996</td>\n",
              "      <td>Rent</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Education</td>\n",
              "      <td>B</td>\n",
              "      <td>20000</td>\n",
              "      <td>12.18</td>\n",
              "      <td>1</td>\n",
              "      <td>0.36</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33357 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       idade  salario situacao_moradia  tempo_trabalho  motivo_emprestimo  \\\n",
              "0         21    60000             Rent             2.0          Education   \n",
              "1         40    70000         Mortgage             6.0          Education   \n",
              "2         29   115000         Mortgage             3.0            Medical   \n",
              "3         26    84996             Rent             0.0            Medical   \n",
              "4         23    54500             Rent             2.0  Debtconsolidation   \n",
              "...      ...      ...              ...             ...                ...   \n",
              "34496     39    33996             Rent             6.0            Medical   \n",
              "34497     24    36000         Mortgage             0.0    Homeimprovement   \n",
              "34498     27    39600         Mortgage            11.0  Debtconsolidation   \n",
              "34499     30    39996         Mortgage             8.0            Medical   \n",
              "34500     26    54996             Rent             8.0          Education   \n",
              "\n",
              "      pontuacao_emprestimo  valor_emprestimo  taxa_juros  inadimplencia  \\\n",
              "0                        B              8000       11.26              0   \n",
              "1                        A             18000        7.90              0   \n",
              "2                        C             22000       15.23              0   \n",
              "3                        B              9000       11.26              0   \n",
              "4                        A              8000        0.00              0   \n",
              "...                    ...               ...         ...            ...   \n",
              "34496                    D              4000        0.00              1   \n",
              "34497                    A             14775        6.62              0   \n",
              "34498                    A              4800        6.76              0   \n",
              "34499                    C             10000       12.73              0   \n",
              "34500                    B             20000       12.18              1   \n",
              "\n",
              "       renda_percentual_emprestimo devendo  tempo_de_credito  \n",
              "0                             0.13       N                 3  \n",
              "1                             0.26       N                14  \n",
              "2                             0.19       Y                 7  \n",
              "3                             0.11       N                 2  \n",
              "4                             0.15       N                 2  \n",
              "...                            ...     ...               ...  \n",
              "34496                         0.12       N                13  \n",
              "34497                         0.41       N                 4  \n",
              "34498                         0.12       N                 9  \n",
              "34499                         0.25       N                 6  \n",
              "34500                         0.36       N                 4  \n",
              "\n",
              "[33357 rows x 12 columns]"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados = dados[(dados['idade'] < 110) & (dados['tempo_trabalho'] < 100)]\n",
        "dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rIsDJJ91MIY"
      },
      "source": [
        "Por fim, alteraremos o tipo de dado da variável `tempo_trabalho` para tipo inteiro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esStDLHxFNZm",
        "outputId": "feec0783-75cd-48e0-da87-7a9e6c53a94a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ricar\\AppData\\Local\\Temp\\ipykernel_1200\\1175232491.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dados['tempo_trabalho'] = dados['tempo_trabalho'].astype('int64')\n"
          ]
        }
      ],
      "source": [
        "dados['tempo_trabalho'] = dados['tempo_trabalho'].astype('int64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assim:\n",
        "* a base de dados passou de 34501 registros para 33357, sendo removidos 1144 retirados do conjunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr2j0nsY01nk"
      },
      "source": [
        "## <h1 style=\"padding:10px;background-color:orange;margin:0;color:black;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 25px 25px;overflow:hidden;font-weight:500\">Tratamento de dados</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3Q3mS_c12DQ"
      },
      "source": [
        "Agora se inicia o processo de tratamento de dados para que possam ser usados na etapa de modelagem.\n",
        "\n",
        "As variáveis categóricas serão transformadas em variáveis *dummy* e as variáveis serão normalizadas para ficarem em uma mesma escala para que variáveis com escalas maiores não tenham peso maior que as outras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y6HiUOFBV-2",
        "outputId": "ca1a048c-3da4-4a64-ffd1-9d299c8c85eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 33357 entries, 0 to 34500\n",
            "Data columns (total 12 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   idade                        33357 non-null  int64  \n",
            " 1   salario                      33357 non-null  int64  \n",
            " 2   situacao_moradia             33357 non-null  object \n",
            " 3   tempo_trabalho               33357 non-null  int64  \n",
            " 4   motivo_emprestimo            33357 non-null  object \n",
            " 5   pontuacao_emprestimo         33357 non-null  object \n",
            " 6   valor_emprestimo             33357 non-null  int64  \n",
            " 7   taxa_juros                   33357 non-null  float64\n",
            " 8   inadimplencia                33357 non-null  int64  \n",
            " 9   renda_percentual_emprestimo  33357 non-null  float64\n",
            " 10  devendo                      33357 non-null  object \n",
            " 11  tempo_de_credito             33357 non-null  int64  \n",
            "dtypes: float64(2), int64(6), object(4)\n",
            "memory usage: 3.3+ MB\n"
          ]
        }
      ],
      "source": [
        "dados.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5eBccVP21FE"
      },
      "source": [
        "Vamos extrair a correlação entre as variáveis numéricas para entender se há alguma relação direta ou indireta entre as variáveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "4F_5_hh5GNok",
        "outputId": "25dfe07a-d49e-427b-920f-8d1d0597745b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idade</th>\n",
              "      <th>salario</th>\n",
              "      <th>tempo_trabalho</th>\n",
              "      <th>valor_emprestimo</th>\n",
              "      <th>taxa_juros</th>\n",
              "      <th>inadimplencia</th>\n",
              "      <th>renda_percentual_emprestimo</th>\n",
              "      <th>tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>idade</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.137635</td>\n",
              "      <td>0.161702</td>\n",
              "      <td>0.049830</td>\n",
              "      <td>0.010599</td>\n",
              "      <td>-0.017246</td>\n",
              "      <td>-0.032974</td>\n",
              "      <td>0.804475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>salario</th>\n",
              "      <td>0.137635</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.161947</td>\n",
              "      <td>0.310228</td>\n",
              "      <td>-0.001445</td>\n",
              "      <td>-0.163050</td>\n",
              "      <td>-0.286127</td>\n",
              "      <td>0.120578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tempo_trabalho</th>\n",
              "      <td>0.161702</td>\n",
              "      <td>0.161947</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.118238</td>\n",
              "      <td>-0.028787</td>\n",
              "      <td>-0.088057</td>\n",
              "      <td>-0.059989</td>\n",
              "      <td>0.142806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valor_emprestimo</th>\n",
              "      <td>0.049830</td>\n",
              "      <td>0.310228</td>\n",
              "      <td>0.118238</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.097055</td>\n",
              "      <td>0.104461</td>\n",
              "      <td>0.563776</td>\n",
              "      <td>0.042435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>taxa_juros</th>\n",
              "      <td>0.010599</td>\n",
              "      <td>-0.001445</td>\n",
              "      <td>-0.028787</td>\n",
              "      <td>0.097055</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.222766</td>\n",
              "      <td>0.081163</td>\n",
              "      <td>0.002211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>inadimplencia</th>\n",
              "      <td>-0.017246</td>\n",
              "      <td>-0.163050</td>\n",
              "      <td>-0.088057</td>\n",
              "      <td>0.104461</td>\n",
              "      <td>0.222766</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.374367</td>\n",
              "      <td>-0.015183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>renda_percentual_emprestimo</th>\n",
              "      <td>-0.032974</td>\n",
              "      <td>-0.286127</td>\n",
              "      <td>-0.059989</td>\n",
              "      <td>0.563776</td>\n",
              "      <td>0.081163</td>\n",
              "      <td>0.374367</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.030991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tempo_de_credito</th>\n",
              "      <td>0.804475</td>\n",
              "      <td>0.120578</td>\n",
              "      <td>0.142806</td>\n",
              "      <td>0.042435</td>\n",
              "      <td>0.002211</td>\n",
              "      <td>-0.015183</td>\n",
              "      <td>-0.030991</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                idade   salario  tempo_trabalho  \\\n",
              "idade                        1.000000  0.137635        0.161702   \n",
              "salario                      0.137635  1.000000        0.161947   \n",
              "tempo_trabalho               0.161702  0.161947        1.000000   \n",
              "valor_emprestimo             0.049830  0.310228        0.118238   \n",
              "taxa_juros                   0.010599 -0.001445       -0.028787   \n",
              "inadimplencia               -0.017246 -0.163050       -0.088057   \n",
              "renda_percentual_emprestimo -0.032974 -0.286127       -0.059989   \n",
              "tempo_de_credito             0.804475  0.120578        0.142806   \n",
              "\n",
              "                             valor_emprestimo  taxa_juros  inadimplencia  \\\n",
              "idade                                0.049830    0.010599      -0.017246   \n",
              "salario                              0.310228   -0.001445      -0.163050   \n",
              "tempo_trabalho                       0.118238   -0.028787      -0.088057   \n",
              "valor_emprestimo                     1.000000    0.097055       0.104461   \n",
              "taxa_juros                           0.097055    1.000000       0.222766   \n",
              "inadimplencia                        0.104461    0.222766       1.000000   \n",
              "renda_percentual_emprestimo          0.563776    0.081163       0.374367   \n",
              "tempo_de_credito                     0.042435    0.002211      -0.015183   \n",
              "\n",
              "                             renda_percentual_emprestimo  tempo_de_credito  \n",
              "idade                                          -0.032974          0.804475  \n",
              "salario                                        -0.286127          0.120578  \n",
              "tempo_trabalho                                 -0.059989          0.142806  \n",
              "valor_emprestimo                                0.563776          0.042435  \n",
              "taxa_juros                                      0.081163          0.002211  \n",
              "inadimplencia                                   0.374367         -0.015183  \n",
              "renda_percentual_emprestimo                     1.000000         -0.030991  \n",
              "tempo_de_credito                               -0.030991          1.000000  "
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "762WkpDy3FsR"
      },
      "source": [
        "Notamos que a variável `renda_percentual_emprestimo` tem uma correlação alta de aproximadamente `57.71%` com `valor_emprestimo` e de fato essa variável é construída utilizando o salário e o valor do empréstimo solicitado pelo cliente.\n",
        "\n",
        "Por isso iremos remover a coluna `renda_percentual_emprestimo`, para não haver informação duplicada no conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "1UcAPAt-Ggb4"
      },
      "outputs": [],
      "source": [
        "dados2 = dados.drop('renda_percentual_emprestimo', axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lNu69Am3yUN"
      },
      "source": [
        "Para o processo de transformação das variáveis categóricas para dummys, é preciso substituir os valores da coluna `devendo` para 0 e 1, uma vez que essa variável possui apenas 2 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "4kSMRZNKGe9U"
      },
      "outputs": [],
      "source": [
        "dicionario = {\n",
        "    'N': 0,\n",
        "    'Y': 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "Aaa3d2fpLnrn"
      },
      "outputs": [],
      "source": [
        "dados2.replace(dicionario, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <h1 style=\"padding:10px;background-color:orange;margin:0;color:black;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 25px 25px;overflow:hidden;font-weight:500\">One Hot Encoding</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-rTiI_tP_bw"
      },
      "source": [
        "Vamos fazer a divisão das variáveis explicativas da variável alvo do conjunto de dados. A variável alvo é a `inadimplencia`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "-xCLXaVvprls"
      },
      "outputs": [],
      "source": [
        "x = dados2.drop(['inadimplencia'], axis = 1)\n",
        "y = dados2['inadimplencia']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idade</th>\n",
              "      <th>salario</th>\n",
              "      <th>situacao_moradia</th>\n",
              "      <th>tempo_trabalho</th>\n",
              "      <th>motivo_emprestimo</th>\n",
              "      <th>pontuacao_emprestimo</th>\n",
              "      <th>valor_emprestimo</th>\n",
              "      <th>taxa_juros</th>\n",
              "      <th>devendo</th>\n",
              "      <th>tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>60000</td>\n",
              "      <td>Rent</td>\n",
              "      <td>2</td>\n",
              "      <td>Education</td>\n",
              "      <td>B</td>\n",
              "      <td>8000</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>70000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>6</td>\n",
              "      <td>Education</td>\n",
              "      <td>A</td>\n",
              "      <td>18000</td>\n",
              "      <td>7.90</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>115000</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>3</td>\n",
              "      <td>Medical</td>\n",
              "      <td>C</td>\n",
              "      <td>22000</td>\n",
              "      <td>15.23</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26</td>\n",
              "      <td>84996</td>\n",
              "      <td>Rent</td>\n",
              "      <td>0</td>\n",
              "      <td>Medical</td>\n",
              "      <td>B</td>\n",
              "      <td>9000</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23</td>\n",
              "      <td>54500</td>\n",
              "      <td>Rent</td>\n",
              "      <td>2</td>\n",
              "      <td>Debtconsolidation</td>\n",
              "      <td>A</td>\n",
              "      <td>8000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   idade  salario situacao_moradia  tempo_trabalho  motivo_emprestimo  \\\n",
              "0     21    60000             Rent               2          Education   \n",
              "1     40    70000         Mortgage               6          Education   \n",
              "2     29   115000         Mortgage               3            Medical   \n",
              "3     26    84996             Rent               0            Medical   \n",
              "4     23    54500             Rent               2  Debtconsolidation   \n",
              "\n",
              "  pontuacao_emprestimo  valor_emprestimo  taxa_juros  devendo  \\\n",
              "0                    B              8000       11.26        0   \n",
              "1                    A             18000        7.90        0   \n",
              "2                    C             22000       15.23        1   \n",
              "3                    B              9000       11.26        0   \n",
              "4                    A              8000        0.00        0   \n",
              "\n",
              "   tempo_de_credito  \n",
              "0                 3  \n",
              "1                14  \n",
              "2                 7  \n",
              "3                 2  \n",
              "4                 2  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: inadimplencia, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(x.head())\n",
        "display(y.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Processo Encoding<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFq8Lc5jQPaB"
      },
      "source": [
        "As variáveis categóricas com mais de 2 categorias precisam passar por um processo de construção de novas colunas. Cada uma das novas colunas corresponde a uma das categorias e o valor será 1 caso o registro tenha a presença da característica e 0 caso contrário\n",
        "\n",
        "Faremos a criação dessas novas colunas com o `OneHotEncoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "wAYqRYO_uFQL"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "tGrZK_WquJcs",
        "outputId": "c275acfc-90a1-47da-f2a4-ef01e2092e34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>onehotencoder__situacao_moradia_Mortgage</th>\n",
              "      <th>onehotencoder__situacao_moradia_Other</th>\n",
              "      <th>onehotencoder__situacao_moradia_Own</th>\n",
              "      <th>onehotencoder__situacao_moradia_Rent</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Debtconsolidation</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Education</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Homeimprovement</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Medical</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Personal</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Venture</th>\n",
              "      <th>...</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_E</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_F</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_G</th>\n",
              "      <th>remainder__idade</th>\n",
              "      <th>remainder__salario</th>\n",
              "      <th>remainder__tempo_trabalho</th>\n",
              "      <th>remainder__valor_emprestimo</th>\n",
              "      <th>remainder__taxa_juros</th>\n",
              "      <th>remainder__devendo</th>\n",
              "      <th>remainder__tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8000.0</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>7.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>115000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22000.0</td>\n",
              "      <td>15.23</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>84996.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>11.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>54500.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8000.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   onehotencoder__situacao_moradia_Mortgage  \\\n",
              "0                                       0.0   \n",
              "1                                       1.0   \n",
              "2                                       1.0   \n",
              "3                                       0.0   \n",
              "4                                       0.0   \n",
              "\n",
              "   onehotencoder__situacao_moradia_Other  onehotencoder__situacao_moradia_Own  \\\n",
              "0                                    0.0                                  0.0   \n",
              "1                                    0.0                                  0.0   \n",
              "2                                    0.0                                  0.0   \n",
              "3                                    0.0                                  0.0   \n",
              "4                                    0.0                                  0.0   \n",
              "\n",
              "   onehotencoder__situacao_moradia_Rent  \\\n",
              "0                                   1.0   \n",
              "1                                   0.0   \n",
              "2                                   0.0   \n",
              "3                                   1.0   \n",
              "4                                   1.0   \n",
              "\n",
              "   onehotencoder__motivo_emprestimo_Debtconsolidation  \\\n",
              "0                                                0.0    \n",
              "1                                                0.0    \n",
              "2                                                0.0    \n",
              "3                                                0.0    \n",
              "4                                                1.0    \n",
              "\n",
              "   onehotencoder__motivo_emprestimo_Education  \\\n",
              "0                                         1.0   \n",
              "1                                         1.0   \n",
              "2                                         0.0   \n",
              "3                                         0.0   \n",
              "4                                         0.0   \n",
              "\n",
              "   onehotencoder__motivo_emprestimo_Homeimprovement  \\\n",
              "0                                               0.0   \n",
              "1                                               0.0   \n",
              "2                                               0.0   \n",
              "3                                               0.0   \n",
              "4                                               0.0   \n",
              "\n",
              "   onehotencoder__motivo_emprestimo_Medical  \\\n",
              "0                                       0.0   \n",
              "1                                       0.0   \n",
              "2                                       1.0   \n",
              "3                                       1.0   \n",
              "4                                       0.0   \n",
              "\n",
              "   onehotencoder__motivo_emprestimo_Personal  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "\n",
              "   onehotencoder__motivo_emprestimo_Venture  ...  \\\n",
              "0                                       0.0  ...   \n",
              "1                                       0.0  ...   \n",
              "2                                       0.0  ...   \n",
              "3                                       0.0  ...   \n",
              "4                                       0.0  ...   \n",
              "\n",
              "   onehotencoder__pontuacao_emprestimo_E  \\\n",
              "0                                    0.0   \n",
              "1                                    0.0   \n",
              "2                                    0.0   \n",
              "3                                    0.0   \n",
              "4                                    0.0   \n",
              "\n",
              "   onehotencoder__pontuacao_emprestimo_F  \\\n",
              "0                                    0.0   \n",
              "1                                    0.0   \n",
              "2                                    0.0   \n",
              "3                                    0.0   \n",
              "4                                    0.0   \n",
              "\n",
              "   onehotencoder__pontuacao_emprestimo_G  remainder__idade  \\\n",
              "0                                    0.0              21.0   \n",
              "1                                    0.0              40.0   \n",
              "2                                    0.0              29.0   \n",
              "3                                    0.0              26.0   \n",
              "4                                    0.0              23.0   \n",
              "\n",
              "   remainder__salario  remainder__tempo_trabalho  remainder__valor_emprestimo  \\\n",
              "0             60000.0                        2.0                       8000.0   \n",
              "1             70000.0                        6.0                      18000.0   \n",
              "2            115000.0                        3.0                      22000.0   \n",
              "3             84996.0                        0.0                       9000.0   \n",
              "4             54500.0                        2.0                       8000.0   \n",
              "\n",
              "   remainder__taxa_juros  remainder__devendo  remainder__tempo_de_credito  \n",
              "0                  11.26                 0.0                          3.0  \n",
              "1                   7.90                 0.0                         14.0  \n",
              "2                  15.23                 1.0                          7.0  \n",
              "3                  11.26                 0.0                          2.0  \n",
              "4                   0.00                 0.0                          2.0  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "colunas_categoricas = ['situacao_moradia','motivo_emprestimo','pontuacao_emprestimo']\n",
        "\n",
        "one_hot_enc = make_column_transformer(\n",
        "    (OneHotEncoder(), colunas_categoricas),\n",
        "    remainder='passthrough')\n",
        "\n",
        "dados_transformados = one_hot_enc.fit_transform(x)\n",
        "dados_transformados = pd.DataFrame(dados_transformados, columns=one_hot_enc.get_feature_names_out())\n",
        "dados_transformados.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF_chECsTjS9"
      },
      "source": [
        "#### Normalização dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw6D35OZU1aU"
      },
      "source": [
        "A escala das variáveis numéricas do conjunto de dados é muito diferente e pode gerar um viés no modelo de machine learning. Desse modo, vamos normalizar os dados, colocando todos em uma mesma escala."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>onehotencoder__situacao_moradia_Mortgage</th>\n",
              "      <th>onehotencoder__situacao_moradia_Other</th>\n",
              "      <th>onehotencoder__situacao_moradia_Own</th>\n",
              "      <th>onehotencoder__situacao_moradia_Rent</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Debtconsolidation</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Education</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Homeimprovement</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Medical</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Personal</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Venture</th>\n",
              "      <th>...</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_E</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_F</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_G</th>\n",
              "      <th>remainder__idade</th>\n",
              "      <th>remainder__salario</th>\n",
              "      <th>remainder__tempo_trabalho</th>\n",
              "      <th>remainder__valor_emprestimo</th>\n",
              "      <th>remainder__taxa_juros</th>\n",
              "      <th>remainder__devendo</th>\n",
              "      <th>remainder__tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.223404</td>\n",
              "      <td>0.029415</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>0.484927</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.425532</td>\n",
              "      <td>0.034317</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>0.340224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.308511</td>\n",
              "      <td>0.056379</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.655900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.178571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276596</td>\n",
              "      <td>0.041669</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.484927</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.244681</td>\n",
              "      <td>0.026719</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33352</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.414894</td>\n",
              "      <td>0.016666</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>0.114286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.392857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33353</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.255319</td>\n",
              "      <td>0.017649</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.422143</td>\n",
              "      <td>0.285099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33354</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.287234</td>\n",
              "      <td>0.019414</td>\n",
              "      <td>0.268293</td>\n",
              "      <td>0.137143</td>\n",
              "      <td>0.291128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33355</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.319149</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.548234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33356</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276596</td>\n",
              "      <td>0.026962</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.524548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33357 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       onehotencoder__situacao_moradia_Mortgage  \\\n",
              "0                                           0.0   \n",
              "1                                           1.0   \n",
              "2                                           1.0   \n",
              "3                                           0.0   \n",
              "4                                           0.0   \n",
              "...                                         ...   \n",
              "33352                                       0.0   \n",
              "33353                                       1.0   \n",
              "33354                                       1.0   \n",
              "33355                                       1.0   \n",
              "33356                                       0.0   \n",
              "\n",
              "       onehotencoder__situacao_moradia_Other  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "...                                      ...   \n",
              "33352                                    0.0   \n",
              "33353                                    0.0   \n",
              "33354                                    0.0   \n",
              "33355                                    0.0   \n",
              "33356                                    0.0   \n",
              "\n",
              "       onehotencoder__situacao_moradia_Own  \\\n",
              "0                                      0.0   \n",
              "1                                      0.0   \n",
              "2                                      0.0   \n",
              "3                                      0.0   \n",
              "4                                      0.0   \n",
              "...                                    ...   \n",
              "33352                                  0.0   \n",
              "33353                                  0.0   \n",
              "33354                                  0.0   \n",
              "33355                                  0.0   \n",
              "33356                                  0.0   \n",
              "\n",
              "       onehotencoder__situacao_moradia_Rent  \\\n",
              "0                                       1.0   \n",
              "1                                       0.0   \n",
              "2                                       0.0   \n",
              "3                                       1.0   \n",
              "4                                       1.0   \n",
              "...                                     ...   \n",
              "33352                                   1.0   \n",
              "33353                                   0.0   \n",
              "33354                                   0.0   \n",
              "33355                                   0.0   \n",
              "33356                                   1.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Debtconsolidation  \\\n",
              "0                                                    0.0    \n",
              "1                                                    0.0    \n",
              "2                                                    0.0    \n",
              "3                                                    0.0    \n",
              "4                                                    1.0    \n",
              "...                                                  ...    \n",
              "33352                                                0.0    \n",
              "33353                                                0.0    \n",
              "33354                                                1.0    \n",
              "33355                                                0.0    \n",
              "33356                                                0.0    \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Education  \\\n",
              "0                                             1.0   \n",
              "1                                             1.0   \n",
              "2                                             0.0   \n",
              "3                                             0.0   \n",
              "4                                             0.0   \n",
              "...                                           ...   \n",
              "33352                                         0.0   \n",
              "33353                                         0.0   \n",
              "33354                                         0.0   \n",
              "33355                                         0.0   \n",
              "33356                                         1.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Homeimprovement  \\\n",
              "0                                                   0.0   \n",
              "1                                                   0.0   \n",
              "2                                                   0.0   \n",
              "3                                                   0.0   \n",
              "4                                                   0.0   \n",
              "...                                                 ...   \n",
              "33352                                               0.0   \n",
              "33353                                               1.0   \n",
              "33354                                               0.0   \n",
              "33355                                               0.0   \n",
              "33356                                               0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Medical  \\\n",
              "0                                           0.0   \n",
              "1                                           0.0   \n",
              "2                                           1.0   \n",
              "3                                           1.0   \n",
              "4                                           0.0   \n",
              "...                                         ...   \n",
              "33352                                       1.0   \n",
              "33353                                       0.0   \n",
              "33354                                       0.0   \n",
              "33355                                       1.0   \n",
              "33356                                       0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Personal  \\\n",
              "0                                            0.0   \n",
              "1                                            0.0   \n",
              "2                                            0.0   \n",
              "3                                            0.0   \n",
              "4                                            0.0   \n",
              "...                                          ...   \n",
              "33352                                        0.0   \n",
              "33353                                        0.0   \n",
              "33354                                        0.0   \n",
              "33355                                        0.0   \n",
              "33356                                        0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Venture  ...  \\\n",
              "0                                           0.0  ...   \n",
              "1                                           0.0  ...   \n",
              "2                                           0.0  ...   \n",
              "3                                           0.0  ...   \n",
              "4                                           0.0  ...   \n",
              "...                                         ...  ...   \n",
              "33352                                       0.0  ...   \n",
              "33353                                       0.0  ...   \n",
              "33354                                       0.0  ...   \n",
              "33355                                       0.0  ...   \n",
              "33356                                       0.0  ...   \n",
              "\n",
              "       onehotencoder__pontuacao_emprestimo_E  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "...                                      ...   \n",
              "33352                                    0.0   \n",
              "33353                                    0.0   \n",
              "33354                                    0.0   \n",
              "33355                                    0.0   \n",
              "33356                                    0.0   \n",
              "\n",
              "       onehotencoder__pontuacao_emprestimo_F  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "...                                      ...   \n",
              "33352                                    0.0   \n",
              "33353                                    0.0   \n",
              "33354                                    0.0   \n",
              "33355                                    0.0   \n",
              "33356                                    0.0   \n",
              "\n",
              "       onehotencoder__pontuacao_emprestimo_G  remainder__idade  \\\n",
              "0                                        0.0          0.223404   \n",
              "1                                        0.0          0.425532   \n",
              "2                                        0.0          0.308511   \n",
              "3                                        0.0          0.276596   \n",
              "4                                        0.0          0.244681   \n",
              "...                                      ...               ...   \n",
              "33352                                    0.0          0.414894   \n",
              "33353                                    0.0          0.255319   \n",
              "33354                                    0.0          0.287234   \n",
              "33355                                    0.0          0.319149   \n",
              "33356                                    0.0          0.276596   \n",
              "\n",
              "       remainder__salario  remainder__tempo_trabalho  \\\n",
              "0                0.029415                   0.048780   \n",
              "1                0.034317                   0.146341   \n",
              "2                0.056379                   0.073171   \n",
              "3                0.041669                   0.000000   \n",
              "4                0.026719                   0.048780   \n",
              "...                   ...                        ...   \n",
              "33352            0.016666                   0.146341   \n",
              "33353            0.017649                   0.000000   \n",
              "33354            0.019414                   0.268293   \n",
              "33355            0.019608                   0.195122   \n",
              "33356            0.026962                   0.195122   \n",
              "\n",
              "       remainder__valor_emprestimo  remainder__taxa_juros  remainder__devendo  \\\n",
              "0                         0.228571               0.484927                 0.0   \n",
              "1                         0.514286               0.340224                 0.0   \n",
              "2                         0.628571               0.655900                 1.0   \n",
              "3                         0.257143               0.484927                 0.0   \n",
              "4                         0.228571               0.000000                 0.0   \n",
              "...                            ...                    ...                 ...   \n",
              "33352                     0.114286               0.000000                 0.0   \n",
              "33353                     0.422143               0.285099                 0.0   \n",
              "33354                     0.137143               0.291128                 0.0   \n",
              "33355                     0.285714               0.548234                 0.0   \n",
              "33356                     0.571429               0.524548                 0.0   \n",
              "\n",
              "       remainder__tempo_de_credito  \n",
              "0                         0.035714  \n",
              "1                         0.428571  \n",
              "2                         0.178571  \n",
              "3                         0.000000  \n",
              "4                         0.000000  \n",
              "...                            ...  \n",
              "33352                     0.392857  \n",
              "33353                     0.071429  \n",
              "33354                     0.250000  \n",
              "33355                     0.142857  \n",
              "33356                     0.071429  \n",
              "\n",
              "[33357 rows x 24 columns]"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(dados_transformados)\n",
        "\n",
        "dados_transformados = scaler.transform(dados_transformados)\n",
        "dados_transformados = pd.DataFrame(dados_transformados, columns = one_hot_enc.get_feature_names_out())\n",
        "dados_transformados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOOQfuMHBnWZ"
      },
      "source": [
        "#### Separação de dados (treino e teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp-0DbEVVlSJ"
      },
      "source": [
        "Para realizar a validação de dados e conseguir avaliar se o modelo está se saindo bem, vamos dividir os dados em conjuntos de treinamento e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20783    0\n",
              "26592    0\n",
              "19476    0\n",
              "11340    0\n",
              "28214    0\n",
              "        ..\n",
              "30590    0\n",
              "24846    0\n",
              "17913    0\n",
              "24049    0\n",
              "28851    0\n",
              "Name: inadimplencia, Length: 8340, dtype: int64"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 144\n",
        "\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(dados_transformados, y, random_state = SEED, stratify = y)\n",
        "y_teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assim o conjunto de dados Treino possui 25017 linhas.\n",
            "E o conjunto de teste possui 8340 linhas.\n"
          ]
        }
      ],
      "source": [
        "print(f'Assim o conjunto de dados Treino possui {x_treino.shape[0]} linhas.')\n",
        "print(f'E o conjunto de teste possui {x_teste.shape[0]} linhas.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <h1 style=\"padding:10px;background-color:orange;margin:0;color:black;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 25px 25px;overflow:hidden;font-weight:500\">Aprendendo</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2A3pFaOR9T2"
      },
      "source": [
        "A Alura Cash deseja identificar os clientes inadimplentes, e essa etapa de modelagem é o foco desse trabalho. Acontece que a variável `inadimplencia` se encontra desbalanceada.\n",
        "\n",
        "Serão usadas duas técnicas de balanceamento de dados, uma de Oversampling e outra de Undersampling e os resultados das duas estratégias serão comparadas com a utilização de 3 algoritmos diferentes.\n",
        "\n",
        "Os algoritmos que serão usados são a Árvore de Decisão, Gradient Boosting e Regressão Logística. Esses modelos foram escolhidos pela explicabilidade que é importante para o problema de negócio que desejamos resolver, que é a análise de risco de inadimplência.\n",
        "\n",
        "A métrica principal a ser analisada é o recall, que indica a proporção de clientes que são inadimplentes mas o modelo não detectou, que podem gerar grande prejuízo para a empresa.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVm3TCR1YMb-"
      },
      "source": [
        "Import de modelos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7ZA8Fn5SZi8"
      },
      "source": [
        "Import de métricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcLAAhFtEP5n"
      },
      "source": [
        "### Aprendizado Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPewcDm8V5Cr"
      },
      "source": [
        "Vamos utilizar a técnica de oversampling SMOTE para balancear a variável alvo, construindo dados sintéticos da categoria com menos frequência."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "D0EkDZJ8TiJB",
        "outputId": "caa306ac-0d29-47b1-e22a-d2bc0b5a01bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>onehotencoder__situacao_moradia_Mortgage</th>\n",
              "      <th>onehotencoder__situacao_moradia_Other</th>\n",
              "      <th>onehotencoder__situacao_moradia_Own</th>\n",
              "      <th>onehotencoder__situacao_moradia_Rent</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Debtconsolidation</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Education</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Homeimprovement</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Medical</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Personal</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Venture</th>\n",
              "      <th>...</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_E</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_F</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_G</th>\n",
              "      <th>remainder__idade</th>\n",
              "      <th>remainder__salario</th>\n",
              "      <th>remainder__tempo_trabalho</th>\n",
              "      <th>remainder__valor_emprestimo</th>\n",
              "      <th>remainder__taxa_juros</th>\n",
              "      <th>remainder__devendo</th>\n",
              "      <th>remainder__tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.414894</td>\n",
              "      <td>0.049172</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.676141</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.234043</td>\n",
              "      <td>0.014707</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.580965</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.071429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276596</td>\n",
              "      <td>0.083342</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>0.584410</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.319149</td>\n",
              "      <td>0.025491</td>\n",
              "      <td>0.121951</td>\n",
              "      <td>0.091429</td>\n",
              "      <td>0.301034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>0.029415</td>\n",
              "      <td>0.219512</td>\n",
              "      <td>0.385714</td>\n",
              "      <td>0.322567</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39199</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225089</td>\n",
              "      <td>0.008597</td>\n",
              "      <td>0.003862</td>\n",
              "      <td>0.091359</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39200</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264765</td>\n",
              "      <td>0.029964</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.688916</td>\n",
              "      <td>0.477497</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39201</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.255319</td>\n",
              "      <td>0.036030</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.392970</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39202</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257201</td>\n",
              "      <td>0.021493</td>\n",
              "      <td>0.159283</td>\n",
              "      <td>0.512128</td>\n",
              "      <td>0.466581</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39203</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.258461</td>\n",
              "      <td>0.011446</td>\n",
              "      <td>0.034374</td>\n",
              "      <td>0.134419</td>\n",
              "      <td>0.381070</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010548</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39204 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       onehotencoder__situacao_moradia_Mortgage  \\\n",
              "0                                           0.0   \n",
              "1                                           0.0   \n",
              "2                                           1.0   \n",
              "3                                           1.0   \n",
              "4                                           0.0   \n",
              "...                                         ...   \n",
              "39199                                       0.0   \n",
              "39200                                       0.0   \n",
              "39201                                       1.0   \n",
              "39202                                       0.0   \n",
              "39203                                       0.0   \n",
              "\n",
              "       onehotencoder__situacao_moradia_Other  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "...                                      ...   \n",
              "39199                                    0.0   \n",
              "39200                                    0.0   \n",
              "39201                                    0.0   \n",
              "39202                                    0.0   \n",
              "39203                                    0.0   \n",
              "\n",
              "       onehotencoder__situacao_moradia_Own  \\\n",
              "0                                      0.0   \n",
              "1                                      0.0   \n",
              "2                                      0.0   \n",
              "3                                      0.0   \n",
              "4                                      0.0   \n",
              "...                                    ...   \n",
              "39199                                  0.0   \n",
              "39200                                  0.0   \n",
              "39201                                  0.0   \n",
              "39202                                  0.0   \n",
              "39203                                  0.0   \n",
              "\n",
              "       onehotencoder__situacao_moradia_Rent  \\\n",
              "0                                       1.0   \n",
              "1                                       1.0   \n",
              "2                                       0.0   \n",
              "3                                       0.0   \n",
              "4                                       1.0   \n",
              "...                                     ...   \n",
              "39199                                   1.0   \n",
              "39200                                   1.0   \n",
              "39201                                   0.0   \n",
              "39202                                   1.0   \n",
              "39203                                   1.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Debtconsolidation  \\\n",
              "0                                                    0.0    \n",
              "1                                                    0.0    \n",
              "2                                                    0.0    \n",
              "3                                                    0.0    \n",
              "4                                                    1.0    \n",
              "...                                                  ...    \n",
              "39199                                                0.0    \n",
              "39200                                                0.0    \n",
              "39201                                                0.0    \n",
              "39202                                                0.0    \n",
              "39203                                                1.0    \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Education  \\\n",
              "0                                             0.0   \n",
              "1                                             0.0   \n",
              "2                                             0.0   \n",
              "3                                             0.0   \n",
              "4                                             0.0   \n",
              "...                                           ...   \n",
              "39199                                         0.0   \n",
              "39200                                         0.0   \n",
              "39201                                         0.0   \n",
              "39202                                         0.0   \n",
              "39203                                         0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Homeimprovement  \\\n",
              "0                                                   0.0   \n",
              "1                                                   1.0   \n",
              "2                                                   0.0   \n",
              "3                                                   0.0   \n",
              "4                                                   0.0   \n",
              "...                                                 ...   \n",
              "39199                                               0.0   \n",
              "39200                                               0.0   \n",
              "39201                                               0.0   \n",
              "39202                                               0.0   \n",
              "39203                                               0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Medical  \\\n",
              "0                                           1.0   \n",
              "1                                           0.0   \n",
              "2                                           0.0   \n",
              "3                                           0.0   \n",
              "4                                           0.0   \n",
              "...                                         ...   \n",
              "39199                                       0.0   \n",
              "39200                                       0.0   \n",
              "39201                                       0.0   \n",
              "39202                                       1.0   \n",
              "39203                                       0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Personal  \\\n",
              "0                                            0.0   \n",
              "1                                            0.0   \n",
              "2                                            0.0   \n",
              "3                                            0.0   \n",
              "4                                            0.0   \n",
              "...                                          ...   \n",
              "39199                                        1.0   \n",
              "39200                                        1.0   \n",
              "39201                                        1.0   \n",
              "39202                                        0.0   \n",
              "39203                                        0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Venture  ...  \\\n",
              "0                                           0.0  ...   \n",
              "1                                           0.0  ...   \n",
              "2                                           1.0  ...   \n",
              "3                                           1.0  ...   \n",
              "4                                           0.0  ...   \n",
              "...                                         ...  ...   \n",
              "39199                                       0.0  ...   \n",
              "39200                                       0.0  ...   \n",
              "39201                                       0.0  ...   \n",
              "39202                                       0.0  ...   \n",
              "39203                                       0.0  ...   \n",
              "\n",
              "       onehotencoder__pontuacao_emprestimo_E  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "...                                      ...   \n",
              "39199                                    0.0   \n",
              "39200                                    0.0   \n",
              "39201                                    0.0   \n",
              "39202                                    0.0   \n",
              "39203                                    0.0   \n",
              "\n",
              "       onehotencoder__pontuacao_emprestimo_F  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "...                                      ...   \n",
              "39199                                    0.0   \n",
              "39200                                    0.0   \n",
              "39201                                    0.0   \n",
              "39202                                    0.0   \n",
              "39203                                    0.0   \n",
              "\n",
              "       onehotencoder__pontuacao_emprestimo_G  remainder__idade  \\\n",
              "0                                        0.0          0.414894   \n",
              "1                                        0.0          0.234043   \n",
              "2                                        0.0          0.276596   \n",
              "3                                        0.0          0.319149   \n",
              "4                                        0.0          0.265957   \n",
              "...                                      ...               ...   \n",
              "39199                                    0.0          0.225089   \n",
              "39200                                    0.0          0.264765   \n",
              "39201                                    0.0          0.255319   \n",
              "39202                                    0.0          0.257201   \n",
              "39203                                    0.0          0.258461   \n",
              "\n",
              "       remainder__salario  remainder__tempo_trabalho  \\\n",
              "0                0.049172                   0.048780   \n",
              "1                0.014707                   0.000000   \n",
              "2                0.083342                   0.000000   \n",
              "3                0.025491                   0.121951   \n",
              "4                0.029415                   0.219512   \n",
              "...                   ...                        ...   \n",
              "39199            0.008597                   0.003862   \n",
              "39200            0.029964                   0.073171   \n",
              "39201            0.036030                   0.017943   \n",
              "39202            0.021493                   0.159283   \n",
              "39203            0.011446                   0.034374   \n",
              "\n",
              "       remainder__valor_emprestimo  remainder__taxa_juros  remainder__devendo  \\\n",
              "0                         0.714286               0.676141                 1.0   \n",
              "1                         0.257143               0.580965                 1.0   \n",
              "2                         0.342857               0.584410                 1.0   \n",
              "3                         0.091429               0.301034                 0.0   \n",
              "4                         0.385714               0.322567                 0.0   \n",
              "...                            ...                    ...                 ...   \n",
              "39199                     0.091359               0.000000                 0.0   \n",
              "39200                     0.688916               0.477497                 0.0   \n",
              "39201                     0.392970               0.000000                 0.0   \n",
              "39202                     0.512128               0.466581                 0.0   \n",
              "39203                     0.134419               0.381070                 0.0   \n",
              "\n",
              "       remainder__tempo_de_credito  \n",
              "0                         0.500000  \n",
              "1                         0.071429  \n",
              "2                         0.000000  \n",
              "3                         0.285714  \n",
              "4                         0.000000  \n",
              "...                            ...  \n",
              "39199                     0.071429  \n",
              "39200                     0.063425  \n",
              "39201                     0.006569  \n",
              "39202                     0.071429  \n",
              "39203                     0.010548  \n",
              "\n",
              "[39204 rows x 24 columns]"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state = SEED)\n",
        "X_balanceado_over, y_balanceado_over = smote.fit_resample(x_treino, y_treino)\n",
        "X_balanceado_over"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_8NkbwaEP5n"
      },
      "source": [
        "#### DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.88      0.90      6535\n",
            "           1       0.63      0.76      0.69      1805\n",
            "\n",
            "    accuracy                           0.85      8340\n",
            "   macro avg       0.78      0.82      0.79      8340\n",
            "weighted avg       0.86      0.85      0.86      8340\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "arvore = DecisionTreeClassifier(random_state=SEED)\n",
        "arvore.fit(X_balanceado_over, y_balanceado_over)\n",
        "\n",
        "previsao_arvore = arvore.predict(x_teste)\n",
        "\n",
        "print(classification_report(y_teste, previsao_arvore))\n",
        "\n",
        "mapa_calor = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"#12239e\",\"#92dfa6\",\"#9cd33b\"])\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(arvore, x_teste, y_teste, cmap = mapa_calor)\n",
        "plt.grid(False)\n",
        "plt.savefig('over-DecisionTree.png', format='png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOkLXfqyEP5p"
      },
      "source": [
        "#### GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.89      0.91      6535\n",
            "           1       0.65      0.75      0.70      1805\n",
            "\n",
            "    accuracy                           0.86      8340\n",
            "   macro avg       0.79      0.82      0.80      8340\n",
            "weighted avg       0.87      0.86      0.86      8340\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "gboost = GradientBoostingClassifier(random_state=SEED)\n",
        "gboost.fit(X_balanceado_over, y_balanceado_over)\n",
        "previsao_gboost = gboost.predict(x_teste)\n",
        "\n",
        "print(classification_report(y_teste, previsao_gboost))\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(gboost, x_teste, y_teste, cmap = mapa_calor)\n",
        "plt.grid(False)\n",
        "plt.savefig('over-GradientBoosting.png', format='png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJvLEOkNEP5r"
      },
      "source": [
        "#### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.76      0.83      6535\n",
            "           1       0.46      0.73      0.56      1805\n",
            "\n",
            "    accuracy                           0.75      8340\n",
            "   macro avg       0.68      0.74      0.69      8340\n",
            "weighted avg       0.81      0.75      0.77      8340\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "reg_logistica = LogisticRegression(random_state=SEED, max_iter =1000)\n",
        "reg_logistica.fit(X_balanceado_over, y_balanceado_over)\n",
        "previsao_reglog = reg_logistica.predict(x_teste)\n",
        "\n",
        "print(classification_report(y_teste, previsao_reglog))\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(reg_logistica, x_teste, y_teste, cmap = mapa_calor)\n",
        "plt.grid(False)\n",
        "plt.savefig('over-LogisticRegression.png', format='png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry_UF9G2axc9"
      },
      "source": [
        "Os resultados dos modelos utilizando a técnica de oversampling foram salvos para posterior comparação com a técnica de undersampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "yA4-86PoFFaF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "metricas_over = pd.DataFrame({'Acurácia treino':[arvore.score(x_treino, y_treino), \n",
        "                                 gboost.score(x_treino, y_treino), \n",
        "                                 reg_logistica.score(x_treino, y_treino)], \n",
        "            'Acurácia teste': [arvore.score(x_teste, y_teste), \n",
        "                                 gboost.score(x_teste, y_teste), \n",
        "                                 reg_logistica.score(x_teste, y_teste)], \n",
        "            'Recall':[recall_score(y_teste, previsao_arvore),\n",
        "                      recall_score(y_teste, previsao_gboost),\n",
        "                      recall_score(y_teste, previsao_reglog)]},\n",
        "             index = ['Árvore de Decisão Oversampling', 'Gradient Boosting Oversampling', 'Regressão Logísitica Oversampling'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acurácia treino</th>\n",
              "      <th>Acurácia teste</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Árvore de Decisão Oversampling</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.851079</td>\n",
              "      <td>0.755125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting Oversampling</th>\n",
              "      <td>0.871208</td>\n",
              "      <td>0.860671</td>\n",
              "      <td>0.752909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Regressão Logísitica Oversampling</th>\n",
              "      <td>0.771835</td>\n",
              "      <td>0.752638</td>\n",
              "      <td>0.727424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Acurácia treino  Acurácia teste    Recall\n",
              "Árvore de Decisão Oversampling            1.000000        0.851079  0.755125\n",
              "Gradient Boosting Oversampling            0.871208        0.860671  0.752909\n",
              "Regressão Logísitica Oversampling         0.771835        0.752638  0.727424"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metricas_over"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCIcgg55LyFv"
      },
      "source": [
        "### Aprendizado Undersampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njoBvyK3a35N"
      },
      "source": [
        "Agora será realizado o balanceamento da variável alvo utilizando a técnica de undersampling, que removerá aleatoriamente registros da classe mais frequente, igualando a quantidade de registros das duas classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "2pheUa30Ytf4",
        "outputId": "51f4965f-ff72-43e7-9846-f8ac0db3cd02"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>onehotencoder__situacao_moradia_Mortgage</th>\n",
              "      <th>onehotencoder__situacao_moradia_Other</th>\n",
              "      <th>onehotencoder__situacao_moradia_Own</th>\n",
              "      <th>onehotencoder__situacao_moradia_Rent</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Debtconsolidation</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Education</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Homeimprovement</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Medical</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Personal</th>\n",
              "      <th>onehotencoder__motivo_emprestimo_Venture</th>\n",
              "      <th>...</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_E</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_F</th>\n",
              "      <th>onehotencoder__pontuacao_emprestimo_G</th>\n",
              "      <th>remainder__idade</th>\n",
              "      <th>remainder__salario</th>\n",
              "      <th>remainder__tempo_trabalho</th>\n",
              "      <th>remainder__valor_emprestimo</th>\n",
              "      <th>remainder__taxa_juros</th>\n",
              "      <th>remainder__devendo</th>\n",
              "      <th>remainder__tempo_de_credito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.468085</td>\n",
              "      <td>0.023532</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.578381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.535714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276596</td>\n",
              "      <td>0.010589</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.430233</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.340426</td>\n",
              "      <td>0.029415</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.203571</td>\n",
              "      <td>0.430233</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.178571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.223404</td>\n",
              "      <td>0.039220</td>\n",
              "      <td>0.121951</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.559432</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>0.075502</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.274286</td>\n",
              "      <td>0.471576</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16240</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372340</td>\n",
              "      <td>0.046587</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.621016</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16241</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436170</td>\n",
              "      <td>0.011766</td>\n",
              "      <td>0.585366</td>\n",
              "      <td>0.057143</td>\n",
              "      <td>0.333764</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.535714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16242</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.297872</td>\n",
              "      <td>0.016668</td>\n",
              "      <td>0.292683</td>\n",
              "      <td>0.105714</td>\n",
              "      <td>0.297588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.214286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16243</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.308511</td>\n",
              "      <td>0.013237</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0.113571</td>\n",
              "      <td>0.524117</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.107143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16244</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.287234</td>\n",
              "      <td>0.082362</td>\n",
              "      <td>0.121951</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.743325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16245 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       onehotencoder__situacao_moradia_Mortgage  \\\n",
              "0                                           0.0   \n",
              "1                                           0.0   \n",
              "2                                           1.0   \n",
              "3                                           1.0   \n",
              "4                                           1.0   \n",
              "...                                         ...   \n",
              "16240                                       0.0   \n",
              "16241                                       0.0   \n",
              "16242                                       1.0   \n",
              "16243                                       0.0   \n",
              "16244                                       1.0   \n",
              "\n",
              "       onehotencoder__situacao_moradia_Other  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "...                                      ...   \n",
              "16240                                    0.0   \n",
              "16241                                    0.0   \n",
              "16242                                    0.0   \n",
              "16243                                    0.0   \n",
              "16244                                    0.0   \n",
              "\n",
              "       onehotencoder__situacao_moradia_Own  \\\n",
              "0                                      0.0   \n",
              "1                                      1.0   \n",
              "2                                      0.0   \n",
              "3                                      0.0   \n",
              "4                                      0.0   \n",
              "...                                    ...   \n",
              "16240                                  0.0   \n",
              "16241                                  0.0   \n",
              "16242                                  0.0   \n",
              "16243                                  0.0   \n",
              "16244                                  0.0   \n",
              "\n",
              "       onehotencoder__situacao_moradia_Rent  \\\n",
              "0                                       1.0   \n",
              "1                                       0.0   \n",
              "2                                       0.0   \n",
              "3                                       0.0   \n",
              "4                                       0.0   \n",
              "...                                     ...   \n",
              "16240                                   1.0   \n",
              "16241                                   1.0   \n",
              "16242                                   0.0   \n",
              "16243                                   1.0   \n",
              "16244                                   0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Debtconsolidation  \\\n",
              "0                                                    0.0    \n",
              "1                                                    0.0    \n",
              "2                                                    0.0    \n",
              "3                                                    0.0    \n",
              "4                                                    1.0    \n",
              "...                                                  ...    \n",
              "16240                                                0.0    \n",
              "16241                                                0.0    \n",
              "16242                                                0.0    \n",
              "16243                                                0.0    \n",
              "16244                                                1.0    \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Education  \\\n",
              "0                                             0.0   \n",
              "1                                             0.0   \n",
              "2                                             0.0   \n",
              "3                                             1.0   \n",
              "4                                             0.0   \n",
              "...                                           ...   \n",
              "16240                                         0.0   \n",
              "16241                                         0.0   \n",
              "16242                                         0.0   \n",
              "16243                                         0.0   \n",
              "16244                                         0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Homeimprovement  \\\n",
              "0                                                   0.0   \n",
              "1                                                   0.0   \n",
              "2                                                   0.0   \n",
              "3                                                   0.0   \n",
              "4                                                   0.0   \n",
              "...                                                 ...   \n",
              "16240                                               1.0   \n",
              "16241                                               0.0   \n",
              "16242                                               1.0   \n",
              "16243                                               1.0   \n",
              "16244                                               0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Medical  \\\n",
              "0                                           1.0   \n",
              "1                                           1.0   \n",
              "2                                           0.0   \n",
              "3                                           0.0   \n",
              "4                                           0.0   \n",
              "...                                         ...   \n",
              "16240                                       0.0   \n",
              "16241                                       0.0   \n",
              "16242                                       0.0   \n",
              "16243                                       0.0   \n",
              "16244                                       0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Personal  \\\n",
              "0                                            0.0   \n",
              "1                                            0.0   \n",
              "2                                            0.0   \n",
              "3                                            0.0   \n",
              "4                                            0.0   \n",
              "...                                          ...   \n",
              "16240                                        0.0   \n",
              "16241                                        1.0   \n",
              "16242                                        0.0   \n",
              "16243                                        0.0   \n",
              "16244                                        0.0   \n",
              "\n",
              "       onehotencoder__motivo_emprestimo_Venture  ...  \\\n",
              "0                                           0.0  ...   \n",
              "1                                           0.0  ...   \n",
              "2                                           1.0  ...   \n",
              "3                                           0.0  ...   \n",
              "4                                           0.0  ...   \n",
              "...                                         ...  ...   \n",
              "16240                                       0.0  ...   \n",
              "16241                                       0.0  ...   \n",
              "16242                                       0.0  ...   \n",
              "16243                                       0.0  ...   \n",
              "16244                                       0.0  ...   \n",
              "\n",
              "       onehotencoder__pontuacao_emprestimo_E  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "...                                      ...   \n",
              "16240                                    0.0   \n",
              "16241                                    0.0   \n",
              "16242                                    0.0   \n",
              "16243                                    0.0   \n",
              "16244                                    0.0   \n",
              "\n",
              "       onehotencoder__pontuacao_emprestimo_F  \\\n",
              "0                                        0.0   \n",
              "1                                        0.0   \n",
              "2                                        0.0   \n",
              "3                                        0.0   \n",
              "4                                        0.0   \n",
              "...                                      ...   \n",
              "16240                                    0.0   \n",
              "16241                                    0.0   \n",
              "16242                                    0.0   \n",
              "16243                                    0.0   \n",
              "16244                                    1.0   \n",
              "\n",
              "       onehotencoder__pontuacao_emprestimo_G  remainder__idade  \\\n",
              "0                                        0.0          0.468085   \n",
              "1                                        0.0          0.276596   \n",
              "2                                        0.0          0.340426   \n",
              "3                                        0.0          0.223404   \n",
              "4                                        0.0          0.265957   \n",
              "...                                      ...               ...   \n",
              "16240                                    0.0          0.372340   \n",
              "16241                                    0.0          0.436170   \n",
              "16242                                    0.0          0.297872   \n",
              "16243                                    0.0          0.308511   \n",
              "16244                                    0.0          0.287234   \n",
              "\n",
              "       remainder__salario  remainder__tempo_trabalho  \\\n",
              "0                0.023532                   0.000000   \n",
              "1                0.010589                   0.000000   \n",
              "2                0.029415                   0.048780   \n",
              "3                0.039220                   0.121951   \n",
              "4                0.075502                   0.024390   \n",
              "...                   ...                        ...   \n",
              "16240            0.046587                   0.048780   \n",
              "16241            0.011766                   0.585366   \n",
              "16242            0.016668                   0.292683   \n",
              "16243            0.013237                   0.243902   \n",
              "16244            0.082362                   0.121951   \n",
              "\n",
              "       remainder__valor_emprestimo  remainder__taxa_juros  remainder__devendo  \\\n",
              "0                         0.142857               0.578381                 0.0   \n",
              "1                         0.120000               0.430233                 0.0   \n",
              "2                         0.203571               0.430233                 0.0   \n",
              "3                         0.142857               0.559432                 0.0   \n",
              "4                         0.274286               0.471576                 0.0   \n",
              "...                            ...                    ...                 ...   \n",
              "16240                     0.142857               0.621016                 1.0   \n",
              "16241                     0.057143               0.333764                 0.0   \n",
              "16242                     0.105714               0.297588                 0.0   \n",
              "16243                     0.113571               0.524117                 0.0   \n",
              "16244                     0.685714               0.743325                 0.0   \n",
              "\n",
              "       remainder__tempo_de_credito  \n",
              "0                         0.535714  \n",
              "1                         0.035714  \n",
              "2                         0.178571  \n",
              "3                         0.000000  \n",
              "4                         0.071429  \n",
              "...                            ...  \n",
              "16240                     0.142857  \n",
              "16241                     0.535714  \n",
              "16242                     0.214286  \n",
              "16243                     0.107143  \n",
              "16244                     0.250000  \n",
              "\n",
              "[16245 rows x 24 columns]"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "under = RandomUnderSampler(random_state=SEED,sampling_strategy=0.5)\n",
        "X_balanceado_under, y_balanceado_under = under.fit_resample(x_treino, y_treino)\n",
        "X_balanceado_under"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Njajgr9L1Yv"
      },
      "source": [
        "#### DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.86      0.89      6535\n",
            "           1       0.60      0.76      0.67      1805\n",
            "\n",
            "    accuracy                           0.84      8340\n",
            "   macro avg       0.77      0.81      0.78      8340\n",
            "weighted avg       0.86      0.84      0.85      8340\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "arvore = DecisionTreeClassifier(random_state=SEED)\n",
        "arvore.fit(X_balanceado_under, y_balanceado_under)\n",
        "previsao_arvore = arvore.predict(x_teste)\n",
        "\n",
        "print(classification_report(y_teste, previsao_arvore))\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(arvore, x_teste, y_teste, cmap = mapa_calor)\n",
        "plt.grid(False)\n",
        "plt.savefig('under-DecisionTree.png', format='png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asle62mNMKjf"
      },
      "source": [
        "#### GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93      6535\n",
            "           1       0.78      0.71      0.74      1805\n",
            "\n",
            "    accuracy                           0.89      8340\n",
            "   macro avg       0.85      0.83      0.84      8340\n",
            "weighted avg       0.89      0.89      0.89      8340\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "gboost = GradientBoostingClassifier(random_state=SEED)\n",
        "gboost.fit(X_balanceado_under, y_balanceado_under)\n",
        "previsao_gboost = gboost.predict(x_teste)\n",
        "\n",
        "print(classification_report(y_teste, previsao_gboost))\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(gboost, x_teste, y_teste, cmap = mapa_calor)\n",
        "plt.grid(False)\n",
        "plt.savefig('under-GradientBoosting.png', format='png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS4gx44CMP_G"
      },
      "source": [
        "#### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89      6535\n",
            "           1       0.62      0.51      0.56      1805\n",
            "\n",
            "    accuracy                           0.83      8340\n",
            "   macro avg       0.74      0.71      0.72      8340\n",
            "weighted avg       0.82      0.83      0.82      8340\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "reg_logistica = LogisticRegression(random_state=SEED, max_iter =1000)\n",
        "reg_logistica.fit(X_balanceado_under, y_balanceado_under)\n",
        "previsao_reglog = reg_logistica.predict(x_teste)\n",
        "\n",
        "print(classification_report(y_teste, previsao_reglog))\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(reg_logistica, x_teste, y_teste, cmap = mapa_calor)\n",
        "plt.grid(False)\n",
        "plt.savefig('under-LogisticRegression.png', format='png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFm24LxYbVOl"
      },
      "source": [
        "Os resultados dos modelos utilizando a técnica de undersampling serão salvos para posterior comparação com a técnica de oversampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "PjFkM5RiFYT9"
      },
      "outputs": [],
      "source": [
        "metricas_under = pd.DataFrame({'Acurácia treino':[arvore.score(x_treino, y_treino), \n",
        "                                 gboost.score(x_treino, y_treino), \n",
        "                                 reg_logistica.score(x_treino, y_treino)], \n",
        "            'Acurácia teste': [arvore.score(x_teste, y_teste), \n",
        "                                 gboost.score(x_teste, y_teste), \n",
        "                                 reg_logistica.score(x_teste, y_teste)], \n",
        "            'Recall':[recall_score(y_teste, previsao_arvore),\n",
        "                      recall_score(y_teste, previsao_gboost),\n",
        "                      recall_score(y_teste, previsao_reglog)]},\n",
        "             index = ['Árvore de Decisão Undersampling', 'Gradient Boosting Undersampling', 'Regressão Logísitica Undersampling'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acurácia treino</th>\n",
              "      <th>Acurácia teste</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Árvore de Decisão Undersampling</th>\n",
              "      <td>0.951873</td>\n",
              "      <td>0.839448</td>\n",
              "      <td>0.759003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting Undersampling</th>\n",
              "      <td>0.903586</td>\n",
              "      <td>0.893046</td>\n",
              "      <td>0.712465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Regressão Logísitica Undersampling</th>\n",
              "      <td>0.831475</td>\n",
              "      <td>0.825540</td>\n",
              "      <td>0.506371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Acurácia treino  Acurácia teste    Recall\n",
              "Árvore de Decisão Undersampling            0.951873        0.839448  0.759003\n",
              "Gradient Boosting Undersampling            0.903586        0.893046  0.712465\n",
              "Regressão Logísitica Undersampling         0.831475        0.825540  0.506371"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metricas_under"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbjF7LrOD-iu"
      },
      "source": [
        "## Comparando samplings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "VYbP-59gE8le",
        "outputId": "424a0263-f5c9-4666-e4c8-4512c6327f1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acurácia treino</th>\n",
              "      <th>Acurácia teste</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Árvore de Decisão Oversampling</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.851079</td>\n",
              "      <td>0.755125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting Oversampling</th>\n",
              "      <td>0.871208</td>\n",
              "      <td>0.860671</td>\n",
              "      <td>0.752909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Regressão Logísitica Oversampling</th>\n",
              "      <td>0.771835</td>\n",
              "      <td>0.752638</td>\n",
              "      <td>0.727424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Acurácia treino  Acurácia teste    Recall\n",
              "Árvore de Decisão Oversampling            1.000000        0.851079  0.755125\n",
              "Gradient Boosting Oversampling            0.871208        0.860671  0.752909\n",
              "Regressão Logísitica Oversampling         0.771835        0.752638  0.727424"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acurácia treino</th>\n",
              "      <th>Acurácia teste</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Árvore de Decisão Undersampling</th>\n",
              "      <td>0.951873</td>\n",
              "      <td>0.839448</td>\n",
              "      <td>0.759003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting Undersampling</th>\n",
              "      <td>0.903586</td>\n",
              "      <td>0.893046</td>\n",
              "      <td>0.712465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Regressão Logísitica Undersampling</th>\n",
              "      <td>0.831475</td>\n",
              "      <td>0.825540</td>\n",
              "      <td>0.506371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Acurácia treino  Acurácia teste    Recall\n",
              "Árvore de Decisão Undersampling            0.951873        0.839448  0.759003\n",
              "Gradient Boosting Undersampling            0.903586        0.893046  0.712465\n",
              "Regressão Logísitica Undersampling         0.831475        0.825540  0.506371"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(metricas_over,metricas_under)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRw0I1qJb0Jr"
      },
      "source": [
        "Analisando as tabelas, foi possível tirar as seguintes conclusões:\n",
        "\n",
        "* A regressão logística apresenta um baixo desempenho em relação aos demais modelos, tanto no oversampling quanto undersampling.\n",
        "* A árvore de decisão apresenta overfitting tanto no oversampling quanto undersampling. Isso ocorre quando desempenho é alto em dados de treino mas não generaliza bem para os dados de teste.\n",
        "* O gradient boosting foi o modelo mais consistente, não apresentando overfiting.\n",
        "\n",
        "Vamos analisar as matrizes de confusão do Gradient Boosting usando as técnicas de oversampling e undersampling:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3UHhOJjHrFO"
      },
      "source": [
        "- Oversampling - gradientBoosting\n",
        "\n",
        "<img src=\"over-GradientBoosting.png\">\n",
        "\n",
        "- Undersampling - gradientBoosting\n",
        "\n",
        "<img src=\"under-GradientBoosting.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2nkOUqbc61X"
      },
      "source": [
        "É possível identificar que o modelo de gradient boosting usando técnica undersampling possui um resultado geral melhor, com menos erros do que o modelo que usa a técnica de oversampling.\n",
        "\n",
        "Apesar de o recall do modelo que usa o oversampling ser melhor, ocasiona em um erro muito maior para os clientes não inadimplentes em relação ao modelo que usa o undersampling, o que pode gerar uma insatisfação muito grande nos clientes e perder grande parte do potencial de lucro da empresa.\n",
        "\n",
        "O modelo escolhido foi o Gradient Boosting usando a técnica de undersampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAWdHZ57mm8W"
      },
      "source": [
        "## Otimização de hiperparâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vTof1DIeZFk"
      },
      "source": [
        "Vamos passar agora para a otimização de hiperparâmetros do modelo selecionado com o GridSearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "R4vVA6cGmmYQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABOclvzmelQh"
      },
      "source": [
        "Parâmetros a serem testados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "ALv5aEgqmXUq"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    \"loss\":[\"deviance\"],\n",
        "    \"max_depth\":[3,5,8],\n",
        "    \"max_features\":[\"log2\",\"sqrt\"],\n",
        "    \"criterion\": [\"friedman_mse\",  \"absolute_error\"],\n",
        "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9],\n",
        "    \"n_estimators\":[10,100]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqCwx2QrRNgn",
        "outputId": "60693233-8aa7-40ef-d8d3-55e3f885202d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "180 fits failed out of a total of 360.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "180 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py\", line 533, in fit\n",
            "    raise ValueError(\n",
            "ValueError: criterion='absolute_error' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.29806094 0.29399815 0.29473684 0.30083102 0.29695291 0.69787627\n",
            " 0.69843029 0.69325946 0.69381348 0.69695291 0.29806094 0.29399815\n",
            " 0.29473684 0.30083102 0.29695291 0.69787627 0.69843029 0.69325946\n",
            " 0.69381348 0.69695291 0.39261311 0.38060942 0.39316713 0.41366574\n",
            " 0.40775623 0.73388735 0.73314866 0.73518006 0.73370268 0.73370268\n",
            " 0.39261311 0.38060942 0.39316713 0.41366574 0.40775623 0.73388735\n",
            " 0.73314866 0.73518006 0.73370268 0.73370268 0.53942752 0.5521699\n",
            " 0.55309326 0.52631579 0.53277932 0.74053555 0.74718375 0.74626039\n",
            " 0.74459834 0.74459834 0.53942752 0.5521699  0.55309326 0.52631579\n",
            " 0.53277932 0.74053555 0.74718375 0.74626039 0.74459834 0.74459834\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "C:\\Users\\ricar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=144),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;, &#x27;absolute_error&#x27;],\n",
              "                         &#x27;loss&#x27;: [&#x27;deviance&#x27;], &#x27;max_depth&#x27;: [3, 5, 8],\n",
              "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
              "                         &#x27;n_estimators&#x27;: [10, 100],\n",
              "                         &#x27;subsample&#x27;: [0.5, 0.618, 0.8, 0.85, 0.9]},\n",
              "             scoring=&#x27;recall&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=144),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;, &#x27;absolute_error&#x27;],\n",
              "                         &#x27;loss&#x27;: [&#x27;deviance&#x27;], &#x27;max_depth&#x27;: [3, 5, 8],\n",
              "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
              "                         &#x27;n_estimators&#x27;: [10, 100],\n",
              "                         &#x27;subsample&#x27;: [0.5, 0.618, 0.8, 0.85, 0.9]},\n",
              "             scoring=&#x27;recall&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=144)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=144)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=144),\n",
              "             param_grid={'criterion': ['friedman_mse', 'absolute_error'],\n",
              "                         'loss': ['deviance'], 'max_depth': [3, 5, 8],\n",
              "                         'max_features': ['log2', 'sqrt'],\n",
              "                         'n_estimators': [10, 100],\n",
              "                         'subsample': [0.5, 0.618, 0.8, 0.85, 0.9]},\n",
              "             scoring='recall', verbose=1)"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search = GridSearchCV(GradientBoostingClassifier(random_state = SEED), parameters,scoring='recall',cv=3,verbose = 1)\n",
        "\n",
        "grid_search.fit(X_balanceado_under, alvo_balanceado_under)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4Ned4Dfq2Wp",
        "outputId": "ae10277c-3f4d-41dd-f660-2c12d75c87d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([7.03335603e-02, 6.33328756e-02, 6.66666031e-02, 6.00011349e-02,\n",
              "        7.09973971e-02, 6.06666803e-01, 6.15000566e-01, 5.79334021e-01,\n",
              "        5.62998454e-01, 5.85668802e-01, 5.56681951e-02, 6.00001017e-02,\n",
              "        6.06664817e-02, 5.93370597e-02, 6.19992415e-02, 5.27665059e-01,\n",
              "        5.59332053e-01, 5.52335183e-01, 5.39000273e-01, 5.60001055e-01,\n",
              "        7.99977779e-02, 9.06645457e-02, 9.79951223e-02, 9.23344294e-02,\n",
              "        9.53342120e-02, 8.26663176e-01, 1.18233267e+00, 1.11366606e+00,\n",
              "        9.12337144e-01, 8.76998663e-01, 8.10016791e-02, 8.46672058e-02,\n",
              "        9.39992269e-02, 1.44668261e-01, 1.00000938e-01, 7.88001617e-01,\n",
              "        8.20663214e-01, 9.04335976e-01, 9.95674213e-01, 9.45663055e-01,\n",
              "        2.04665581e-01, 2.17663685e-01, 2.32667446e-01, 2.35002120e-01,\n",
              "        2.54000664e-01, 1.99666572e+00, 2.37933238e+00, 2.56666613e+00,\n",
              "        2.31333256e+00, 2.57133420e+00, 2.31000821e-01, 2.56669680e-01,\n",
              "        2.68998146e-01, 2.24666993e-01, 2.36666520e-01, 1.95933112e+00,\n",
              "        2.07666492e+00, 2.23066759e+00, 2.15599783e+00, 2.39400005e+00,\n",
              "        2.33745575e-03, 2.00557709e-03, 2.33761470e-03, 2.00215975e-03,\n",
              "        2.66933441e-03, 5.33914566e-03, 3.00184886e-03, 2.66981125e-03,\n",
              "        4.33238347e-03, 3.67077192e-03, 2.33769417e-03, 3.00280253e-03,\n",
              "        2.33427684e-03, 2.33674049e-03, 2.66909599e-03, 4.00288900e-03,\n",
              "        2.33681997e-03, 2.00279554e-03, 2.00438499e-03, 1.99937820e-03,\n",
              "        2.00343132e-03, 2.00263659e-03, 2.00319290e-03, 2.33562787e-03,\n",
              "        2.00192134e-03, 2.00271606e-03, 2.00843811e-03, 2.33642260e-03,\n",
              "        4.33333715e-03, 2.67481804e-03, 2.33705839e-03, 3.99931272e-03,\n",
              "        3.33635012e-03, 3.33189964e-03, 3.01098824e-03, 3.00526619e-03,\n",
              "        2.67457962e-03, 4.01035945e-03, 3.34111849e-03, 2.00676918e-03,\n",
              "        2.33467420e-03, 2.00716654e-03, 2.00676918e-03, 2.00780233e-03,\n",
              "        2.00406710e-03, 2.00335185e-03, 2.00255712e-03, 2.00033188e-03,\n",
              "        2.00740496e-03, 2.33538946e-03, 1.67059898e-03, 2.33809153e-03,\n",
              "        2.00359027e-03, 2.33697891e-03, 1.67028109e-03, 2.00549761e-03,\n",
              "        2.00231870e-03, 1.67250633e-03, 1.33570035e-03, 1.66996320e-03]),\n",
              " 'std_fit_time': array([2.62595264e-03, 1.69658871e-03, 6.65007082e-03, 2.53068341e-06,\n",
              "        7.11626467e-03, 7.03737857e-03, 4.55218951e-02, 1.02749031e-02,\n",
              "        4.54835357e-03, 5.73360884e-03, 9.43865125e-04, 4.00057251e-06,\n",
              "        1.69953475e-03, 4.73284254e-04, 8.16729731e-04, 1.46546797e-02,\n",
              "        2.85774208e-02, 1.60495153e-02, 2.82721513e-03, 1.46932453e-02,\n",
              "        8.15955765e-04, 1.15562117e-02, 9.92674111e-03, 1.70064265e-03,\n",
              "        6.12787080e-03, 6.62465044e-02, 1.52109885e-01, 1.64198608e-01,\n",
              "        2.16697860e-02, 2.19231642e-02, 8.19455774e-04, 9.42066378e-04,\n",
              "        2.82861551e-03, 3.39094454e-02, 3.55566438e-03, 2.77982814e-02,\n",
              "        3.49251481e-02, 2.18521807e-02, 5.66215248e-02, 2.03720013e-02,\n",
              "        1.22837103e-02, 2.30419075e-02, 6.94573341e-03, 9.89915498e-03,\n",
              "        2.29053769e-02, 1.12868174e-01, 2.08088646e-01, 2.49363009e-01,\n",
              "        2.19287182e-01, 2.48170279e-01, 1.95102935e-02, 3.28852003e-02,\n",
              "        2.37217244e-02, 4.18949273e-03, 4.19039641e-03, 1.41752639e-01,\n",
              "        7.40866589e-02, 1.28856051e-01, 2.49121138e-02, 2.56386074e-01,\n",
              "        4.69853077e-04, 8.12255977e-04, 4.68392067e-04, 4.89903609e-07,\n",
              "        4.67686753e-04, 2.86568824e-03, 8.17511647e-04, 9.44596297e-04,\n",
              "        1.24430597e-03, 2.35156940e-03, 4.66987244e-04, 8.16943788e-04,\n",
              "        4.69069972e-04, 4.73737337e-04, 9.43587866e-04, 8.13819724e-04,\n",
              "        4.69797234e-04, 3.42932526e-06, 8.12155337e-04, 2.93942166e-06,\n",
              "        1.03008599e-06, 3.16497608e-06, 2.19379643e-06, 4.69123168e-04,\n",
              "        4.67338258e-06, 2.14134750e-06, 3.02205934e-06, 4.70585586e-04,\n",
              "        2.62392476e-03, 9.39946090e-04, 4.71145933e-04, 2.15935757e-03,\n",
              "        1.24123013e-03, 4.71052648e-04, 8.25633338e-04, 8.13907347e-04,\n",
              "        4.72858560e-04, 1.42985173e-03, 1.24855650e-03, 3.05944706e-06,\n",
              "        4.67439931e-04, 3.46231793e-06, 2.43140197e-06, 7.07620916e-06,\n",
              "        8.77806426e-07, 1.51207428e-06, 9.79807218e-07, 3.50402318e-06,\n",
              "        2.34680542e-06, 4.72162874e-04, 4.69182362e-04, 4.72944838e-04,\n",
              "        2.97360213e-07, 4.67673140e-04, 4.69123532e-04, 1.43491984e-06,\n",
              "        1.25153985e-06, 4.69864046e-04, 4.69969904e-04, 4.69068598e-04]),\n",
              " 'mean_score_time': array([0.00966724, 0.00700037, 0.00866548, 0.00633279, 0.00933123,\n",
              "        0.01533238, 0.01699893, 0.01499979, 0.01466664, 0.01433031,\n",
              "        0.00666531, 0.0066665 , 0.00599972, 0.00666293, 0.00833559,\n",
              "        0.0146668 , 0.01399922, 0.01600003, 0.01366703, 0.01466719,\n",
              "        0.00700164, 0.00900086, 0.00766714, 0.00733717, 0.00699862,\n",
              "        0.02100102, 0.03966594, 0.0240016 , 0.02066549, 0.01966643,\n",
              "        0.00733105, 0.00733582, 0.00833416, 0.01499708, 0.00733439,\n",
              "        0.02000038, 0.02000149, 0.02133004, 0.02499437, 0.02099959,\n",
              "        0.00866834, 0.00866699, 0.00867105, 0.00899704, 0.0086658 ,\n",
              "        0.04000211, 0.03600025, 0.0316658 , 0.03166564, 0.03233329,\n",
              "        0.01499915, 0.01166304, 0.01066828, 0.00866644, 0.00899967,\n",
              "        0.03400008, 0.03166755, 0.03466558, 0.03100189, 0.03500144,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]),\n",
              " 'std_score_time': array([3.08960254e-03, 2.92865845e-06, 3.77253644e-03, 4.71595177e-04,\n",
              "        1.69786775e-03, 1.24695882e-03, 1.63258292e-03, 8.15269588e-04,\n",
              "        4.71257962e-04, 4.70924811e-04, 4.71764538e-04, 4.71426560e-04,\n",
              "        2.24783192e-07, 4.72446506e-04, 1.88750447e-03, 4.73226026e-04,\n",
              "        1.78416128e-06, 2.83125712e-03, 4.70808436e-04, 4.71989722e-04,\n",
              "        2.86763804e-06, 2.16134117e-03, 4.71765421e-04, 4.76709203e-04,\n",
              "        2.97360213e-07, 2.54064677e-06, 1.11427266e-02, 4.96923514e-03,\n",
              "        9.44878574e-04, 4.75087094e-04, 4.71937170e-04, 4.67400975e-04,\n",
              "        1.24821197e-03, 9.19884757e-03, 4.75304697e-04, 8.14495569e-04,\n",
              "        8.13810597e-04, 2.05571315e-03, 5.65627576e-03, 2.94260021e-03,\n",
              "        4.72497518e-04, 4.71876929e-04, 4.74068751e-04, 2.61416184e-06,\n",
              "        4.71377147e-04, 5.09864999e-03, 5.71376890e-03, 9.41897776e-04,\n",
              "        4.70422366e-04, 1.24778776e-03, 7.78979596e-03, 3.09402440e-03,\n",
              "        3.09370756e-03, 9.42459734e-04, 8.16729638e-04, 3.55834387e-03,\n",
              "        9.44538993e-04, 4.49559692e-03, 8.14492242e-04, 4.96670761e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
              " 'param_criterion': masked_array(data=['friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
              "                    'absolute_error', 'absolute_error', 'absolute_error'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_loss': masked_array(data=['deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance',\n",
              "                    'deviance', 'deviance', 'deviance', 'deviance'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
              "                    8, 8, 8, 8, 8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "                    3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 8, 8, 8, 8, 8,\n",
              "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_features': masked_array(data=['log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_n_estimators': masked_array(data=[10, 10, 10, 10, 10, 100, 100, 100, 100, 100, 10, 10,\n",
              "                    10, 10, 10, 100, 100, 100, 100, 100, 10, 10, 10, 10,\n",
              "                    10, 100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 100,\n",
              "                    100, 100, 100, 100, 10, 10, 10, 10, 10, 100, 100, 100,\n",
              "                    100, 100, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
              "                    10, 10, 10, 10, 10, 100, 100, 100, 100, 100, 10, 10,\n",
              "                    10, 10, 10, 100, 100, 100, 100, 100, 10, 10, 10, 10,\n",
              "                    10, 100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 100,\n",
              "                    100, 100, 100, 100, 10, 10, 10, 10, 10, 100, 100, 100,\n",
              "                    100, 100, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_subsample': masked_array(data=[0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9,\n",
              "                    0.5, 0.618, 0.8, 0.85, 0.9, 0.5, 0.618, 0.8, 0.85, 0.9],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'friedman_mse',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 3,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 5,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'log2',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 10,\n",
              "   'subsample': 0.9},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.5},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.618},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.8},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.85},\n",
              "  {'criterion': 'absolute_error',\n",
              "   'loss': 'deviance',\n",
              "   'max_depth': 8,\n",
              "   'max_features': 'sqrt',\n",
              "   'n_estimators': 100,\n",
              "   'subsample': 0.9}],\n",
              " 'split0_test_score': array([0.32520776, 0.31080332, 0.30914127, 0.30858726, 0.30803324,\n",
              "        0.69916898, 0.70415512, 0.70193906, 0.69695291, 0.70360111,\n",
              "        0.32520776, 0.31080332, 0.30914127, 0.30858726, 0.30803324,\n",
              "        0.69916898, 0.70415512, 0.70193906, 0.69695291, 0.70360111,\n",
              "        0.37562327, 0.37396122, 0.3900277 , 0.43822715, 0.433241  ,\n",
              "        0.74072022, 0.73961219, 0.74182825, 0.74459834, 0.74792244,\n",
              "        0.37562327, 0.37396122, 0.3900277 , 0.43822715, 0.433241  ,\n",
              "        0.74072022, 0.73961219, 0.74182825, 0.74459834, 0.74792244,\n",
              "        0.52243767, 0.55069252, 0.57174515, 0.53462604, 0.54182825,\n",
              "        0.74626039, 0.7567867 , 0.75235457, 0.75180055, 0.75235457,\n",
              "        0.52243767, 0.55069252, 0.57174515, 0.53462604, 0.54182825,\n",
              "        0.74626039, 0.7567867 , 0.75235457, 0.75180055, 0.75235457,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan]),\n",
              " 'split1_test_score': array([0.27700831, 0.28254848, 0.29473684, 0.29916898, 0.29529086,\n",
              "        0.68476454, 0.68531856, 0.67922438, 0.68587258, 0.68587258,\n",
              "        0.27700831, 0.28254848, 0.29473684, 0.29916898, 0.29529086,\n",
              "        0.68476454, 0.68531856, 0.67922438, 0.68587258, 0.68587258,\n",
              "        0.38725762, 0.37617729, 0.38504155, 0.40055402, 0.38891967,\n",
              "        0.71745152, 0.72742382, 0.72742382, 0.71966759, 0.71855956,\n",
              "        0.38725762, 0.37617729, 0.38504155, 0.40055402, 0.38891967,\n",
              "        0.71745152, 0.72742382, 0.72742382, 0.71966759, 0.71855956,\n",
              "        0.55180055, 0.54072022, 0.51191136, 0.52465374, 0.51135734,\n",
              "        0.72631579, 0.73240997, 0.73573407, 0.73130194, 0.73905817,\n",
              "        0.55180055, 0.54072022, 0.51191136, 0.52465374, 0.51135734,\n",
              "        0.72631579, 0.73240997, 0.73573407, 0.73130194, 0.73905817,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan]),\n",
              " 'split2_test_score': array([0.29196676, 0.28864266, 0.28033241, 0.29473684, 0.28753463,\n",
              "        0.70969529, 0.70581717, 0.69861496, 0.69861496, 0.70138504,\n",
              "        0.29196676, 0.28864266, 0.28033241, 0.29473684, 0.28753463,\n",
              "        0.70969529, 0.70581717, 0.69861496, 0.69861496, 0.70138504,\n",
              "        0.41495845, 0.39168975, 0.40443213, 0.40221607, 0.40110803,\n",
              "        0.7434903 , 0.73240997, 0.73628809, 0.73684211, 0.73462604,\n",
              "        0.41495845, 0.39168975, 0.40443213, 0.40221607, 0.40110803,\n",
              "        0.7434903 , 0.73240997, 0.73628809, 0.73684211, 0.73462604,\n",
              "        0.54404432, 0.56509695, 0.57562327, 0.51966759, 0.54515235,\n",
              "        0.74903047, 0.75235457, 0.75069252, 0.75069252, 0.74238227,\n",
              "        0.54404432, 0.56509695, 0.57562327, 0.51966759, 0.54515235,\n",
              "        0.74903047, 0.75235457, 0.75069252, 0.75069252, 0.74238227,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan]),\n",
              " 'mean_test_score': array([0.29806094, 0.29399815, 0.29473684, 0.30083102, 0.29695291,\n",
              "        0.69787627, 0.69843029, 0.69325946, 0.69381348, 0.69695291,\n",
              "        0.29806094, 0.29399815, 0.29473684, 0.30083102, 0.29695291,\n",
              "        0.69787627, 0.69843029, 0.69325946, 0.69381348, 0.69695291,\n",
              "        0.39261311, 0.38060942, 0.39316713, 0.41366574, 0.40775623,\n",
              "        0.73388735, 0.73314866, 0.73518006, 0.73370268, 0.73370268,\n",
              "        0.39261311, 0.38060942, 0.39316713, 0.41366574, 0.40775623,\n",
              "        0.73388735, 0.73314866, 0.73518006, 0.73370268, 0.73370268,\n",
              "        0.53942752, 0.5521699 , 0.55309326, 0.52631579, 0.53277932,\n",
              "        0.74053555, 0.74718375, 0.74626039, 0.74459834, 0.74459834,\n",
              "        0.53942752, 0.5521699 , 0.55309326, 0.52631579, 0.53277932,\n",
              "        0.74053555, 0.74718375, 0.74626039, 0.74459834, 0.74459834,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan]),\n",
              " 'std_test_score': array([0.02014367, 0.01214071, 0.01176117, 0.00577525, 0.00845065,\n",
              "        0.0102189 , 0.00929619, 0.01001666, 0.00565592, 0.00788704,\n",
              "        0.02014367, 0.01214071, 0.01176117, 0.00577525, 0.00845065,\n",
              "        0.0102189 , 0.00929619, 0.01001666, 0.00565592, 0.00788704,\n",
              "        0.01649899, 0.00788704, 0.00822154, 0.01738078, 0.01869481,\n",
              "        0.01167678, 0.00500322, 0.00593255, 0.01041721, 0.01200511,\n",
              "        0.01649899, 0.00788704, 0.00822154, 0.01738078, 0.01869481,\n",
              "        0.01167678, 0.00500322, 0.00593255, 0.01041721, 0.01200511,\n",
              "        0.01242392, 0.01000644, 0.02916301, 0.00621882, 0.01520829,\n",
              "        0.01011828, 0.01060218, 0.00747409, 0.00941285, 0.00564988,\n",
              "        0.01242392, 0.01000644, 0.02916301, 0.00621882, 0.01520829,\n",
              "        0.01011828, 0.01060218, 0.00747409, 0.00941285, 0.00564988,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan]),\n",
              " 'rank_test_score': array([ 53,  59,  57,  51,  55,  23,  21,  29,  27,  25,  53,  59,  57,\n",
              "         51,  55,  23,  21,  29,  27,  25,  47,  49,  45,  41,  43,  13,\n",
              "         19,  11,  15,  15,  47,  49,  45,  41,  43,  13,  19,  11,  15,\n",
              "         15,  35,  33,  31,  39,  37,   9,   1,   3,   5,   5,  35,  33,\n",
              "         31,  39,  37,   9,   1,   3,   5,   5,  93,  94,  95,  96,  97,\n",
              "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
              "        111, 112, 113, 114, 115, 116, 117, 118,  90,  91, 119,  89,  76,\n",
              "         71,  70,  66,  68,  67,  72,  65,  64,  63,  62,  61,  69,  73,\n",
              "         88,  75,  74,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,\n",
              "         87,  92, 120])}"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "qwhFlLBvqi2L"
      },
      "outputs": [],
      "source": [
        "previsao_grid_search = grid_search.best_estimator_\n",
        "previsao_grid = previsao_grid_search.predict(x_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF4Y2zc9e3X0"
      },
      "source": [
        "Retornando o melhor estimador encontrado pelo Grid Search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULlliIZMGQW-",
        "outputId": "0ae726b3-f5e4-4742-aa01-ddb9923f8a04"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(loss=&#x27;deviance&#x27;, max_depth=8, max_features=&#x27;log2&#x27;,\n",
              "                           random_state=144, subsample=0.618)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(loss=&#x27;deviance&#x27;, max_depth=8, max_features=&#x27;log2&#x27;,\n",
              "                           random_state=144, subsample=0.618)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GradientBoostingClassifier(loss='deviance', max_depth=8, max_features='log2',\n",
              "                           random_state=144, subsample=0.618)"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2e4MlmC_yen",
        "outputId": "272d21fe-02ab-4707-fe82-9808545e3109"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'alvo_teste' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ricar\\OneDrive\\Documentos 1\\Dev_Project\\projetos pessoais\\desafio data science\\semana - 2\\alura_cash_dados_gerais.ipynb Célula: 117\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ricar/OneDrive/Documentos%201/Dev_Project/projetos%20pessoais/desafio%20data%20science/semana%20-%202/alura_cash_dados_gerais.ipynb#Y244sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(alvo_teste, previsao_grid))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'alvo_teste' is not defined"
          ]
        }
      ],
      "source": [
        "print(classification_report(alvo_teste, previsao_grid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "-FAeHXjwWD3J",
        "outputId": "b7271eb8-e4c8-4eee-90aa-fd95c0150596"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ConfusionMatrixDisplay.from_estimator(previsao_grid_search, x_teste, alvo_teste, cmap = mapa_calor)\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clwm9kXUgBCZ"
      },
      "source": [
        "Através do resultado, podemos verificar que o desempenho aumentou, principalmente entre os clientes não inadimplentes e esse será o modelo que será colocado em produção."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKCNTZHEhDiD"
      },
      "source": [
        "## Resumo\n",
        "\n",
        "> Primeiramente, coletamos os dados da semana 1 e iniciamos uma análise focada no tratamento de dados para serem inseridos em um modelo de ML. Desse modo, removemos valores nulos e outliers presentes nos dados, bem como aplicamos o balanceamento, normalização e enconding para tratar o conjunto de dados.\n",
        "\n",
        "> Assim, construimos três modelos de aprendizado de máquina pensando na explicabilidade do resultado final, comparamos o desempenho deles para o projeto e escolhemos o que teve melhor performance. Com isso, buscamos melhorar ainda mais o resultado final do modelo com uma otimização de hiperparâmetros e, assim que obtivemos um bom produto final, salvamos o modelo fazendo sua exportação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErflHBMOA7OG"
      },
      "source": [
        "## Exportando modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZjj_auQfRW4"
      },
      "source": [
        "Iremos exportar os modelos para que possam ser utilizados futuramente fora do ambiente do Google Colaboratory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb1gj14531-j"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD3zWY9QfYcp"
      },
      "source": [
        "Modelo one hot encoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mlm2WxT-A-wN"
      },
      "outputs": [],
      "source": [
        "with open('one_hot_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(one_hot_enc, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp9h5c9ufa2f"
      },
      "source": [
        "Modelo de normalização dos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4SpUCJnqtfV"
      },
      "outputs": [],
      "source": [
        "with open('scaler.pkl', 'wb') as file:\n",
        "    pickle.dump(scaler, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQy-_zu2fc9f"
      },
      "source": [
        "Modelo do gradient boosting do grid search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsQayP_EINAl"
      },
      "outputs": [],
      "source": [
        "with open('modelo_treinado.pkl', 'wb') as file:\n",
        "    pickle.dump(previsao_grid_search, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "7eddbd8c5bf552713241dc26cdadfe57f3887154aafba57b3b4991476c427eb5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
